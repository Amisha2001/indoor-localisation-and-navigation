{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9538676d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import math\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "41d83ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "positions = ['(1,1)','(1,2)','(1,3)','(1,4)','(2,1)','(2,2)','(2,3)','(2,4)']\n",
    "df = pd.DataFrame()\n",
    "for i in range(len(positions)):\n",
    "    df1 = pd.read_csv(\"data/raw/data1/lib_\"+positions[i]+\".csv\", names = ['mac_address','rssi_value'], header=None)\n",
    "    starting_mac_address = df1[\"mac_address\"][0]\n",
    "    list_rows = []\n",
    "    dictionary = {}\n",
    "    for row in df1.values:\n",
    "        if row[0] == starting_mac_address:\n",
    "            if len(dictionary) > 0:\n",
    "                dictionary['position'] = positions[i]\n",
    "                list_rows.append(dictionary)\n",
    "            dictionary = {}\n",
    "            dictionary[row[0]]=row[1]\n",
    "        else:\n",
    "            dictionary[row[0]]=row[1]\n",
    "    df1 = pd.DataFrame.from_dict(list_rows)\n",
    "    df = pd.concat([df, df1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d44af190",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop = True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f3be905e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2b2d40c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00:78:88:2C:80:10</th>\n",
       "      <th>00:78:88:28:05:BF</th>\n",
       "      <th>00:C1:64:8A:85:8F</th>\n",
       "      <th>00:78:88:2C:80:1F</th>\n",
       "      <th>00:C1:64:C3:84:7F</th>\n",
       "      <th>00:78:88:81:10:FF</th>\n",
       "      <th>00:78:88:2E:72:2F</th>\n",
       "      <th>00:78:88:2E:72:20</th>\n",
       "      <th>00:C1:64:C3:84:70</th>\n",
       "      <th>00:78:88:18:1D:2F</th>\n",
       "      <th>...</th>\n",
       "      <th>00:C1:64:8A:85:80</th>\n",
       "      <th>00:78:88:2B:53:10</th>\n",
       "      <th>00:78:88:28:0F:90</th>\n",
       "      <th>00:78:88:4F:06:60</th>\n",
       "      <th>00:78:88:81:10:F0</th>\n",
       "      <th>00:78:88:4F:06:6F</th>\n",
       "      <th>00:78:88:2B:53:1F</th>\n",
       "      <th>00:C1:64:F2:F4:50</th>\n",
       "      <th>00:78:88:2E:72:5F</th>\n",
       "      <th>00:78:88:2E:75:10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-53</td>\n",
       "      <td>-69</td>\n",
       "      <td>-77.0</td>\n",
       "      <td>-56.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-86.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-68.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-74.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-79.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-57</td>\n",
       "      <td>-59</td>\n",
       "      <td>-65.0</td>\n",
       "      <td>-54.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-79.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-69.0</td>\n",
       "      <td>-76.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-78.0</td>\n",
       "      <td>-79.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-69</td>\n",
       "      <td>-61</td>\n",
       "      <td>-78.0</td>\n",
       "      <td>-60.0</td>\n",
       "      <td>-78.0</td>\n",
       "      <td>-79.0</td>\n",
       "      <td>-80.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-75.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-80.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-63</td>\n",
       "      <td>-54</td>\n",
       "      <td>-78.0</td>\n",
       "      <td>-62.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-87.0</td>\n",
       "      <td>-86.0</td>\n",
       "      <td>-81.0</td>\n",
       "      <td>-77.0</td>\n",
       "      <td>-89.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-72.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-66</td>\n",
       "      <td>-57</td>\n",
       "      <td>-78.0</td>\n",
       "      <td>-66.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-81.0</td>\n",
       "      <td>-86.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-83.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-80.0</td>\n",
       "      <td>-74.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-78.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>-55</td>\n",
       "      <td>-60</td>\n",
       "      <td>-65.0</td>\n",
       "      <td>-56.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-80.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-79.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-68.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-79.0</td>\n",
       "      <td>-86.0</td>\n",
       "      <td>-79.0</td>\n",
       "      <td>-79.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>-52</td>\n",
       "      <td>-68</td>\n",
       "      <td>-74.0</td>\n",
       "      <td>-52.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-86.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-75.0</td>\n",
       "      <td>-74.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-66.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-70.0</td>\n",
       "      <td>-88.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-87.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>-64</td>\n",
       "      <td>-60</td>\n",
       "      <td>-79.0</td>\n",
       "      <td>-59.0</td>\n",
       "      <td>-79.0</td>\n",
       "      <td>-79.0</td>\n",
       "      <td>-79.0</td>\n",
       "      <td>-81.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-81.0</td>\n",
       "      <td>-73.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-87.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>-65</td>\n",
       "      <td>-53</td>\n",
       "      <td>-76.0</td>\n",
       "      <td>-62.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-87.0</td>\n",
       "      <td>-85.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-77.0</td>\n",
       "      <td>-87.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-76.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>-70</td>\n",
       "      <td>-56</td>\n",
       "      <td>-75.0</td>\n",
       "      <td>-65.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-79.0</td>\n",
       "      <td>-81.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-79.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-79.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-71.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-78.0</td>\n",
       "      <td>-78.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>384 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     00:78:88:2C:80:10  00:78:88:28:05:BF  00:C1:64:8A:85:8F  \\\n",
       "0                  -53                -69              -77.0   \n",
       "1                  -57                -59              -65.0   \n",
       "2                  -69                -61              -78.0   \n",
       "3                  -63                -54              -78.0   \n",
       "4                  -66                -57              -78.0   \n",
       "..                 ...                ...                ...   \n",
       "379                -55                -60              -65.0   \n",
       "380                -52                -68              -74.0   \n",
       "381                -64                -60              -79.0   \n",
       "382                -65                -53              -76.0   \n",
       "383                -70                -56              -75.0   \n",
       "\n",
       "     00:78:88:2C:80:1F  00:C1:64:C3:84:7F  00:78:88:81:10:FF  \\\n",
       "0                -56.0                NaN                NaN   \n",
       "1                -54.0                NaN                NaN   \n",
       "2                -60.0              -78.0              -79.0   \n",
       "3                -62.0                NaN              -87.0   \n",
       "4                -66.0                NaN              -81.0   \n",
       "..                 ...                ...                ...   \n",
       "379              -56.0                NaN                NaN   \n",
       "380              -52.0                NaN                NaN   \n",
       "381              -59.0              -79.0              -79.0   \n",
       "382              -62.0                NaN              -87.0   \n",
       "383              -65.0                NaN              -79.0   \n",
       "\n",
       "     00:78:88:2E:72:2F  00:78:88:2E:72:20  00:C1:64:C3:84:70  \\\n",
       "0                  NaN                NaN              -86.0   \n",
       "1                -79.0                NaN                NaN   \n",
       "2                -80.0                NaN              -75.0   \n",
       "3                -86.0              -81.0              -77.0   \n",
       "4                -86.0                NaN                NaN   \n",
       "..                 ...                ...                ...   \n",
       "379              -80.0                NaN              -79.0   \n",
       "380              -86.0                NaN                NaN   \n",
       "381              -79.0              -81.0                NaN   \n",
       "382              -85.0                NaN              -77.0   \n",
       "383              -81.0                NaN              -79.0   \n",
       "\n",
       "     00:78:88:18:1D:2F  ... 00:C1:64:8A:85:80  00:78:88:2B:53:10  \\\n",
       "0                  NaN  ...               NaN                NaN   \n",
       "1                  NaN  ...             -69.0              -76.0   \n",
       "2                  NaN  ...               NaN                NaN   \n",
       "3                -89.0  ...             -72.0                NaN   \n",
       "4                  NaN  ...             -83.0                NaN   \n",
       "..                 ...  ...               ...                ...   \n",
       "379                NaN  ...             -68.0                NaN   \n",
       "380                NaN  ...             -75.0              -74.0   \n",
       "381                NaN  ...             -81.0              -73.0   \n",
       "382              -87.0  ...             -76.0                NaN   \n",
       "383                NaN  ...               NaN              -79.0   \n",
       "\n",
       "     00:78:88:28:0F:90  00:78:88:4F:06:60  00:78:88:81:10:F0  \\\n",
       "0                  NaN              -68.0                NaN   \n",
       "1                  NaN                NaN                NaN   \n",
       "2                  NaN                NaN                NaN   \n",
       "3                  NaN                NaN                NaN   \n",
       "4                -80.0              -74.0                NaN   \n",
       "..                 ...                ...                ...   \n",
       "379                NaN              -79.0              -86.0   \n",
       "380                NaN              -66.0                NaN   \n",
       "381                NaN                NaN              -87.0   \n",
       "382                NaN                NaN                NaN   \n",
       "383                NaN              -71.0                NaN   \n",
       "\n",
       "     00:78:88:4F:06:6F  00:78:88:2B:53:1F  00:C1:64:F2:F4:50  \\\n",
       "0                -74.0                NaN                NaN   \n",
       "1                -78.0              -79.0                NaN   \n",
       "2                -80.0                NaN                NaN   \n",
       "3                  NaN                NaN                NaN   \n",
       "4                -78.0                NaN                NaN   \n",
       "..                 ...                ...                ...   \n",
       "379              -79.0              -79.0                NaN   \n",
       "380              -70.0              -88.0                NaN   \n",
       "381                NaN                NaN                NaN   \n",
       "382                NaN                NaN                NaN   \n",
       "383              -78.0              -78.0                NaN   \n",
       "\n",
       "     00:78:88:2E:72:5F  00:78:88:2E:75:10  \n",
       "0                -79.0                NaN  \n",
       "1                  NaN                NaN  \n",
       "2                  NaN                NaN  \n",
       "3                  NaN                NaN  \n",
       "4                  NaN                NaN  \n",
       "..                 ...                ...  \n",
       "379                NaN                NaN  \n",
       "380              -87.0                NaN  \n",
       "381                NaN                NaN  \n",
       "382                NaN                NaN  \n",
       "383                NaN                NaN  \n",
       "\n",
       "[384 rows x 26 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "32722206",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5e7c1c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df = df.loc[:, df.isin([' ','NULL',0, np.nan]).mean() < .75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ced3f08c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00:78:88:2C:80:10</th>\n",
       "      <th>00:78:88:28:05:BF</th>\n",
       "      <th>00:C1:64:8A:85:8F</th>\n",
       "      <th>00:78:88:2C:80:1F</th>\n",
       "      <th>00:78:88:81:10:FF</th>\n",
       "      <th>00:78:88:2E:72:2F</th>\n",
       "      <th>00:78:88:2E:72:20</th>\n",
       "      <th>00:C1:64:C3:84:70</th>\n",
       "      <th>position</th>\n",
       "      <th>00:78:88:28:05:B0</th>\n",
       "      <th>00:C1:64:F2:F3:50</th>\n",
       "      <th>00:78:88:18:1D:20</th>\n",
       "      <th>00:C1:64:8A:85:80</th>\n",
       "      <th>00:78:88:2B:53:10</th>\n",
       "      <th>00:78:88:4F:06:60</th>\n",
       "      <th>00:78:88:4F:06:6F</th>\n",
       "      <th>00:78:88:2B:53:1F</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-53</td>\n",
       "      <td>-69</td>\n",
       "      <td>-77.0</td>\n",
       "      <td>-56.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-86.0</td>\n",
       "      <td>(2,4)</td>\n",
       "      <td>-70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-68.0</td>\n",
       "      <td>-74.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-57</td>\n",
       "      <td>-59</td>\n",
       "      <td>-65.0</td>\n",
       "      <td>-54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-79.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(2,3)</td>\n",
       "      <td>-72.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-69.0</td>\n",
       "      <td>-76.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-78.0</td>\n",
       "      <td>-79.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-69</td>\n",
       "      <td>-61</td>\n",
       "      <td>-78.0</td>\n",
       "      <td>-60.0</td>\n",
       "      <td>-79.0</td>\n",
       "      <td>-80.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-75.0</td>\n",
       "      <td>(2,2)</td>\n",
       "      <td>-58.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-79.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-80.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-63</td>\n",
       "      <td>-54</td>\n",
       "      <td>-78.0</td>\n",
       "      <td>-62.0</td>\n",
       "      <td>-87.0</td>\n",
       "      <td>-86.0</td>\n",
       "      <td>-81.0</td>\n",
       "      <td>-77.0</td>\n",
       "      <td>(2,1)</td>\n",
       "      <td>-50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-71.0</td>\n",
       "      <td>-72.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-66</td>\n",
       "      <td>-57</td>\n",
       "      <td>-78.0</td>\n",
       "      <td>-66.0</td>\n",
       "      <td>-81.0</td>\n",
       "      <td>-86.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(1,2)</td>\n",
       "      <td>-56.0</td>\n",
       "      <td>-87.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-83.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-74.0</td>\n",
       "      <td>-78.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   00:78:88:2C:80:10  00:78:88:28:05:BF  00:C1:64:8A:85:8F  00:78:88:2C:80:1F  \\\n",
       "0                -53                -69              -77.0              -56.0   \n",
       "1                -57                -59              -65.0              -54.0   \n",
       "2                -69                -61              -78.0              -60.0   \n",
       "3                -63                -54              -78.0              -62.0   \n",
       "4                -66                -57              -78.0              -66.0   \n",
       "\n",
       "   00:78:88:81:10:FF  00:78:88:2E:72:2F  00:78:88:2E:72:20  00:C1:64:C3:84:70  \\\n",
       "0                0.0                0.0                0.0              -86.0   \n",
       "1                0.0              -79.0                0.0                0.0   \n",
       "2              -79.0              -80.0                0.0              -75.0   \n",
       "3              -87.0              -86.0              -81.0              -77.0   \n",
       "4              -81.0              -86.0                0.0                0.0   \n",
       "\n",
       "  position  00:78:88:28:05:B0  00:C1:64:F2:F3:50  00:78:88:18:1D:20  \\\n",
       "0    (2,4)              -70.0                0.0                0.0   \n",
       "1    (2,3)              -72.0                0.0                0.0   \n",
       "2    (2,2)              -58.0                0.0              -79.0   \n",
       "3    (2,1)              -50.0                0.0              -71.0   \n",
       "4    (1,2)              -56.0              -87.0                0.0   \n",
       "\n",
       "   00:C1:64:8A:85:80  00:78:88:2B:53:10  00:78:88:4F:06:60  00:78:88:4F:06:6F  \\\n",
       "0                0.0                0.0              -68.0              -74.0   \n",
       "1              -69.0              -76.0                0.0              -78.0   \n",
       "2                0.0                0.0                0.0              -80.0   \n",
       "3              -72.0                0.0                0.0                0.0   \n",
       "4              -83.0                0.0              -74.0              -78.0   \n",
       "\n",
       "   00:78:88:2B:53:1F  \n",
       "0                0.0  \n",
       "1              -79.0  \n",
       "2                0.0  \n",
       "3                0.0  \n",
       "4                0.0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "41c108dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_18824\\897347208.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['position']= label_encoder_pos.fit_transform(df['position'])\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "  \n",
    "label_encoder_pos = preprocessing.LabelEncoder()\n",
    "  \n",
    "df['position']= label_encoder_pos.fit_transform(df['position'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c1f997ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['(1,1)' '(1,2)' '(1,3)' '(1,4)' '(2,1)' '(2,2)' '(2,3)' '(2,4)']\n"
     ]
    }
   ],
   "source": [
    "print(label_encoder_pos.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fbaa326b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00:78:88:2C:80:10</th>\n",
       "      <th>00:78:88:28:05:BF</th>\n",
       "      <th>00:C1:64:8A:85:8F</th>\n",
       "      <th>00:78:88:2C:80:1F</th>\n",
       "      <th>00:78:88:81:10:FF</th>\n",
       "      <th>00:78:88:2E:72:2F</th>\n",
       "      <th>00:78:88:2E:72:20</th>\n",
       "      <th>00:C1:64:C3:84:70</th>\n",
       "      <th>position</th>\n",
       "      <th>00:78:88:28:05:B0</th>\n",
       "      <th>00:C1:64:F2:F3:50</th>\n",
       "      <th>00:78:88:18:1D:20</th>\n",
       "      <th>00:C1:64:8A:85:80</th>\n",
       "      <th>00:78:88:2B:53:10</th>\n",
       "      <th>00:78:88:4F:06:60</th>\n",
       "      <th>00:78:88:4F:06:6F</th>\n",
       "      <th>00:78:88:2B:53:1F</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-53</td>\n",
       "      <td>-69</td>\n",
       "      <td>-77.0</td>\n",
       "      <td>-56.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-86.0</td>\n",
       "      <td>7</td>\n",
       "      <td>-70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-68.0</td>\n",
       "      <td>-74.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-57</td>\n",
       "      <td>-59</td>\n",
       "      <td>-65.0</td>\n",
       "      <td>-54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-79.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>-72.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-69.0</td>\n",
       "      <td>-76.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-78.0</td>\n",
       "      <td>-79.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-69</td>\n",
       "      <td>-61</td>\n",
       "      <td>-78.0</td>\n",
       "      <td>-60.0</td>\n",
       "      <td>-79.0</td>\n",
       "      <td>-80.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-75.0</td>\n",
       "      <td>5</td>\n",
       "      <td>-58.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-79.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-80.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-63</td>\n",
       "      <td>-54</td>\n",
       "      <td>-78.0</td>\n",
       "      <td>-62.0</td>\n",
       "      <td>-87.0</td>\n",
       "      <td>-86.0</td>\n",
       "      <td>-81.0</td>\n",
       "      <td>-77.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-71.0</td>\n",
       "      <td>-72.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-66</td>\n",
       "      <td>-57</td>\n",
       "      <td>-78.0</td>\n",
       "      <td>-66.0</td>\n",
       "      <td>-81.0</td>\n",
       "      <td>-86.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-56.0</td>\n",
       "      <td>-87.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-83.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-74.0</td>\n",
       "      <td>-78.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>-55</td>\n",
       "      <td>-60</td>\n",
       "      <td>-65.0</td>\n",
       "      <td>-56.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-80.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-79.0</td>\n",
       "      <td>6</td>\n",
       "      <td>-66.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-79.0</td>\n",
       "      <td>-79.0</td>\n",
       "      <td>-79.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>-52</td>\n",
       "      <td>-68</td>\n",
       "      <td>-74.0</td>\n",
       "      <td>-52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-86.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>-56.0</td>\n",
       "      <td>-83.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-75.0</td>\n",
       "      <td>-74.0</td>\n",
       "      <td>-66.0</td>\n",
       "      <td>-70.0</td>\n",
       "      <td>-88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>-64</td>\n",
       "      <td>-60</td>\n",
       "      <td>-79.0</td>\n",
       "      <td>-59.0</td>\n",
       "      <td>-79.0</td>\n",
       "      <td>-79.0</td>\n",
       "      <td>-81.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>-60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-81.0</td>\n",
       "      <td>-73.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>-65</td>\n",
       "      <td>-53</td>\n",
       "      <td>-76.0</td>\n",
       "      <td>-62.0</td>\n",
       "      <td>-87.0</td>\n",
       "      <td>-85.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-77.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-53.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-69.0</td>\n",
       "      <td>-76.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>-70</td>\n",
       "      <td>-56</td>\n",
       "      <td>-75.0</td>\n",
       "      <td>-65.0</td>\n",
       "      <td>-79.0</td>\n",
       "      <td>-81.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-79.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-55.0</td>\n",
       "      <td>-82.0</td>\n",
       "      <td>-84.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-79.0</td>\n",
       "      <td>-71.0</td>\n",
       "      <td>-78.0</td>\n",
       "      <td>-78.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>384 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     00:78:88:2C:80:10  00:78:88:28:05:BF  00:C1:64:8A:85:8F  \\\n",
       "0                  -53                -69              -77.0   \n",
       "1                  -57                -59              -65.0   \n",
       "2                  -69                -61              -78.0   \n",
       "3                  -63                -54              -78.0   \n",
       "4                  -66                -57              -78.0   \n",
       "..                 ...                ...                ...   \n",
       "379                -55                -60              -65.0   \n",
       "380                -52                -68              -74.0   \n",
       "381                -64                -60              -79.0   \n",
       "382                -65                -53              -76.0   \n",
       "383                -70                -56              -75.0   \n",
       "\n",
       "     00:78:88:2C:80:1F  00:78:88:81:10:FF  00:78:88:2E:72:2F  \\\n",
       "0                -56.0                0.0                0.0   \n",
       "1                -54.0                0.0              -79.0   \n",
       "2                -60.0              -79.0              -80.0   \n",
       "3                -62.0              -87.0              -86.0   \n",
       "4                -66.0              -81.0              -86.0   \n",
       "..                 ...                ...                ...   \n",
       "379              -56.0                0.0              -80.0   \n",
       "380              -52.0                0.0              -86.0   \n",
       "381              -59.0              -79.0              -79.0   \n",
       "382              -62.0              -87.0              -85.0   \n",
       "383              -65.0              -79.0              -81.0   \n",
       "\n",
       "     00:78:88:2E:72:20  00:C1:64:C3:84:70  position  00:78:88:28:05:B0  \\\n",
       "0                  0.0              -86.0         7              -70.0   \n",
       "1                  0.0                0.0         6              -72.0   \n",
       "2                  0.0              -75.0         5              -58.0   \n",
       "3                -81.0              -77.0         4              -50.0   \n",
       "4                  0.0                0.0         1              -56.0   \n",
       "..                 ...                ...       ...                ...   \n",
       "379                0.0              -79.0         6              -66.0   \n",
       "380                0.0                0.0         3              -56.0   \n",
       "381              -81.0                0.0         5              -60.0   \n",
       "382                0.0              -77.0         4              -53.0   \n",
       "383                0.0              -79.0         1              -55.0   \n",
       "\n",
       "     00:C1:64:F2:F3:50  00:78:88:18:1D:20  00:C1:64:8A:85:80  \\\n",
       "0                  0.0                0.0                0.0   \n",
       "1                  0.0                0.0              -69.0   \n",
       "2                  0.0              -79.0                0.0   \n",
       "3                  0.0              -71.0              -72.0   \n",
       "4                -87.0                0.0              -83.0   \n",
       "..                 ...                ...                ...   \n",
       "379                0.0                0.0              -68.0   \n",
       "380              -83.0                0.0              -75.0   \n",
       "381                0.0                0.0              -81.0   \n",
       "382                0.0              -69.0              -76.0   \n",
       "383              -82.0              -84.0                0.0   \n",
       "\n",
       "     00:78:88:2B:53:10  00:78:88:4F:06:60  00:78:88:4F:06:6F  \\\n",
       "0                  0.0              -68.0              -74.0   \n",
       "1                -76.0                0.0              -78.0   \n",
       "2                  0.0                0.0              -80.0   \n",
       "3                  0.0                0.0                0.0   \n",
       "4                  0.0              -74.0              -78.0   \n",
       "..                 ...                ...                ...   \n",
       "379                0.0              -79.0              -79.0   \n",
       "380              -74.0              -66.0              -70.0   \n",
       "381              -73.0                0.0                0.0   \n",
       "382                0.0                0.0                0.0   \n",
       "383              -79.0              -71.0              -78.0   \n",
       "\n",
       "     00:78:88:2B:53:1F  \n",
       "0                  0.0  \n",
       "1                -79.0  \n",
       "2                  0.0  \n",
       "3                  0.0  \n",
       "4                  0.0  \n",
       "..                 ...  \n",
       "379              -79.0  \n",
       "380              -88.0  \n",
       "381                0.0  \n",
       "382                0.0  \n",
       "383              -78.0  \n",
       "\n",
       "[384 rows x 17 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "935f511e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop(['position'], axis=1)\n",
    "y = df['position']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4795488f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split  \n",
    "x_train, x_test, y_train, y_test= train_test_split(x, y, test_size= 0.25, random_state=0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "08b21a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f80fce",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2a4f1d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier  \n",
    "classifier= RandomForestClassifier()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fd7b155a",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = { \n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth' : [4,5,6,7,8, 20],\n",
    "    'criterion' :['gini', 'entropy']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "483fed98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;],\n",
       "                         &#x27;max_depth&#x27;: [4, 5, 6, 7, 8, 20],\n",
       "                         &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;, &#x27;log2&#x27;],\n",
       "                         &#x27;n_estimators&#x27;: [100, 200, 500]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;],\n",
       "                         &#x27;max_depth&#x27;: [4, 5, 6, 7, 8, 20],\n",
       "                         &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;, &#x27;log2&#x27;],\n",
       "                         &#x27;n_estimators&#x27;: [100, 200, 500]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [4, 5, 6, 7, 8, 20],\n",
       "                         'max_features': ['auto', 'sqrt', 'log2'],\n",
       "                         'n_estimators': [100, 200, 500]})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "CV_rfc = GridSearchCV(estimator=classifier, param_grid=param_grid, cv= 5)\n",
    "CV_rfc.fit(x_train, y_train)\n",
    "#CV_rfc.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "be611823",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1a055f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(CV_rfc, open('model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ccfe07f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The best estimator across ALL searched params:\n",
      " RandomForestClassifier(max_depth=4, max_features='auto')\n",
      "\n",
      " The best score across ALL searched params:\n",
      " 1.0\n",
      "\n",
      " The best parameters across ALL searched params:\n",
      " {'criterion': 'gini', 'max_depth': 4, 'max_features': 'auto', 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n The best estimator across ALL searched params:\\n\",CV_rfc.best_estimator_)\n",
    "print(\"\\n The best score across ALL searched params:\\n\",CV_rfc.best_score_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\",CV_rfc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4e391814",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e19ac831",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred= CV_rfc.predict(x_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "65ede4fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8,  0,  0,  0,  3,  0,  0,  0],\n",
       "       [ 0,  7,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0, 11,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0, 15,  0,  1,  0,  1],\n",
       "       [ 2,  0,  0,  0,  7,  0,  0,  0],\n",
       "       [ 0,  1,  0,  0,  0,  9,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  2, 16,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0, 13]], dtype=int64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e6587117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8958333333333334"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ccf8a9",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "14f83f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split  \n",
    "x_train, x_test, y_train, y_test= train_test_split(x, y, test_size= 0.25, random_state=0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "291445bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB  \n",
    "classifier = GaussianNB()  \n",
    "classifier.fit(x_train, y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "898f1402",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(classifier, open('naive_bayes.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "db117d49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 6, 6, 4, 7, 2, 5, 1, 4, 1, 6, 7, 2, 2, 6, 7, 6, 6, 0, 0, 6, 6,\n",
       "       0, 1, 2, 1, 0, 5, 1, 7, 1, 6, 7, 7, 6, 3, 2, 6, 3, 2, 3, 2, 0, 4,\n",
       "       3, 4, 7, 3, 1, 0, 3, 0, 6, 4, 0, 3, 0, 4, 3, 7, 3, 7, 1, 4, 3, 0,\n",
       "       0, 3, 5, 6, 2, 6, 0, 2, 0, 3, 7, 7, 0, 2, 0, 6, 0, 6, 3, 3, 4, 7,\n",
       "       6, 2, 5, 0, 5, 7, 3, 5])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = classifier.predict(x_test)  \n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "989ea2a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9166666666666666"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898b6476",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "60082618",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ac2940b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288, 16)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "69b97c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.values.reshape(-1, 1, 16)\n",
    "x_test = x_test.values.reshape(-1, 1, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b816ab4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "Y_train_encoded = to_categorical(y_train)\n",
    "Y_test_encoded = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fd2d1d02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-60., -75., -80., -64., -81., -81.,   0.,   0., -49.,   0., -77.,\n",
       "        -80.,   0.,   0.,   0.,   0.]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d0f43bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 128)               74240     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 8)                 72        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 85,312\n",
      "Trainable params: 85,312\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(1,16)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(8, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer = 'adam', metrics=['accuracy'])\n",
    "# fit network\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e5d8dce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "72/72 - 5s - loss: 1.9349 - accuracy: 0.2500 - val_loss: 1.6996 - val_accuracy: 0.3229 - 5s/epoch - 67ms/step\n",
      "Epoch 2/500\n",
      "72/72 - 0s - loss: 1.5261 - accuracy: 0.3819 - val_loss: 1.3767 - val_accuracy: 0.4062 - 429ms/epoch - 6ms/step\n",
      "Epoch 3/500\n",
      "72/72 - 0s - loss: 1.1913 - accuracy: 0.5417 - val_loss: 1.1434 - val_accuracy: 0.5729 - 335ms/epoch - 5ms/step\n",
      "Epoch 4/500\n",
      "72/72 - 0s - loss: 0.9975 - accuracy: 0.6424 - val_loss: 1.0038 - val_accuracy: 0.6042 - 451ms/epoch - 6ms/step\n",
      "Epoch 5/500\n",
      "72/72 - 0s - loss: 0.8415 - accuracy: 0.6597 - val_loss: 0.8550 - val_accuracy: 0.6354 - 329ms/epoch - 5ms/step\n",
      "Epoch 6/500\n",
      "72/72 - 0s - loss: 0.7658 - accuracy: 0.6771 - val_loss: 0.7533 - val_accuracy: 0.7188 - 301ms/epoch - 4ms/step\n",
      "Epoch 7/500\n",
      "72/72 - 0s - loss: 0.6932 - accuracy: 0.7257 - val_loss: 0.6856 - val_accuracy: 0.7500 - 295ms/epoch - 4ms/step\n",
      "Epoch 8/500\n",
      "72/72 - 0s - loss: 0.6296 - accuracy: 0.7604 - val_loss: 0.6879 - val_accuracy: 0.8021 - 312ms/epoch - 4ms/step\n",
      "Epoch 9/500\n",
      "72/72 - 0s - loss: 0.6036 - accuracy: 0.7569 - val_loss: 0.6430 - val_accuracy: 0.7708 - 301ms/epoch - 4ms/step\n",
      "Epoch 10/500\n",
      "72/72 - 0s - loss: 0.5698 - accuracy: 0.7847 - val_loss: 0.7114 - val_accuracy: 0.6979 - 379ms/epoch - 5ms/step\n",
      "Epoch 11/500\n",
      "72/72 - 0s - loss: 0.5587 - accuracy: 0.7674 - val_loss: 0.6795 - val_accuracy: 0.7188 - 434ms/epoch - 6ms/step\n",
      "Epoch 12/500\n",
      "72/72 - 0s - loss: 0.5080 - accuracy: 0.7951 - val_loss: 0.6455 - val_accuracy: 0.8229 - 303ms/epoch - 4ms/step\n",
      "Epoch 13/500\n",
      "72/72 - 0s - loss: 0.4975 - accuracy: 0.8021 - val_loss: 0.7555 - val_accuracy: 0.7188 - 310ms/epoch - 4ms/step\n",
      "Epoch 14/500\n",
      "72/72 - 0s - loss: 0.4821 - accuracy: 0.8160 - val_loss: 0.6683 - val_accuracy: 0.8125 - 382ms/epoch - 5ms/step\n",
      "Epoch 15/500\n",
      "72/72 - 0s - loss: 0.4562 - accuracy: 0.8125 - val_loss: 0.6533 - val_accuracy: 0.7917 - 425ms/epoch - 6ms/step\n",
      "Epoch 16/500\n",
      "72/72 - 0s - loss: 0.4224 - accuracy: 0.8299 - val_loss: 0.7291 - val_accuracy: 0.7500 - 321ms/epoch - 4ms/step\n",
      "Epoch 17/500\n",
      "72/72 - 0s - loss: 0.4162 - accuracy: 0.8333 - val_loss: 0.6403 - val_accuracy: 0.8021 - 434ms/epoch - 6ms/step\n",
      "Epoch 18/500\n",
      "72/72 - 0s - loss: 0.3715 - accuracy: 0.8611 - val_loss: 0.6870 - val_accuracy: 0.8021 - 304ms/epoch - 4ms/step\n",
      "Epoch 19/500\n",
      "72/72 - 0s - loss: 0.3397 - accuracy: 0.8715 - val_loss: 0.7021 - val_accuracy: 0.7917 - 273ms/epoch - 4ms/step\n",
      "Epoch 20/500\n",
      "72/72 - 0s - loss: 0.3498 - accuracy: 0.8611 - val_loss: 0.5459 - val_accuracy: 0.7812 - 268ms/epoch - 4ms/step\n",
      "Epoch 21/500\n",
      "72/72 - 0s - loss: 0.3514 - accuracy: 0.8681 - val_loss: 0.5375 - val_accuracy: 0.8125 - 280ms/epoch - 4ms/step\n",
      "Epoch 22/500\n",
      "72/72 - 0s - loss: 0.3552 - accuracy: 0.8611 - val_loss: 0.7104 - val_accuracy: 0.8125 - 279ms/epoch - 4ms/step\n",
      "Epoch 23/500\n",
      "72/72 - 0s - loss: 0.3475 - accuracy: 0.8438 - val_loss: 0.6276 - val_accuracy: 0.8021 - 271ms/epoch - 4ms/step\n",
      "Epoch 24/500\n",
      "72/72 - 0s - loss: 0.3805 - accuracy: 0.8438 - val_loss: 0.7618 - val_accuracy: 0.7917 - 302ms/epoch - 4ms/step\n",
      "Epoch 25/500\n",
      "72/72 - 0s - loss: 0.3410 - accuracy: 0.8542 - val_loss: 0.6630 - val_accuracy: 0.7708 - 279ms/epoch - 4ms/step\n",
      "Epoch 26/500\n",
      "72/72 - 0s - loss: 0.2928 - accuracy: 0.8819 - val_loss: 0.7484 - val_accuracy: 0.7708 - 292ms/epoch - 4ms/step\n",
      "Epoch 27/500\n",
      "72/72 - 0s - loss: 0.3001 - accuracy: 0.8646 - val_loss: 0.7220 - val_accuracy: 0.7708 - 269ms/epoch - 4ms/step\n",
      "Epoch 28/500\n",
      "72/72 - 0s - loss: 0.3058 - accuracy: 0.8715 - val_loss: 0.6684 - val_accuracy: 0.8021 - 278ms/epoch - 4ms/step\n",
      "Epoch 29/500\n",
      "72/72 - 0s - loss: 0.3055 - accuracy: 0.8646 - val_loss: 0.7276 - val_accuracy: 0.7917 - 279ms/epoch - 4ms/step\n",
      "Epoch 30/500\n",
      "72/72 - 0s - loss: 0.3152 - accuracy: 0.8438 - val_loss: 0.6693 - val_accuracy: 0.7812 - 292ms/epoch - 4ms/step\n",
      "Epoch 31/500\n",
      "72/72 - 0s - loss: 0.2673 - accuracy: 0.8854 - val_loss: 0.7329 - val_accuracy: 0.7604 - 292ms/epoch - 4ms/step\n",
      "Epoch 32/500\n",
      "72/72 - 0s - loss: 0.2871 - accuracy: 0.8681 - val_loss: 0.8687 - val_accuracy: 0.7500 - 282ms/epoch - 4ms/step\n",
      "Epoch 33/500\n",
      "72/72 - 0s - loss: 0.2861 - accuracy: 0.8750 - val_loss: 0.6674 - val_accuracy: 0.7917 - 312ms/epoch - 4ms/step\n",
      "Epoch 34/500\n",
      "72/72 - 0s - loss: 0.2780 - accuracy: 0.8889 - val_loss: 0.7108 - val_accuracy: 0.8021 - 340ms/epoch - 5ms/step\n",
      "Epoch 35/500\n",
      "72/72 - 0s - loss: 0.3306 - accuracy: 0.8403 - val_loss: 0.5854 - val_accuracy: 0.8125 - 301ms/epoch - 4ms/step\n",
      "Epoch 36/500\n",
      "72/72 - 0s - loss: 0.2756 - accuracy: 0.8611 - val_loss: 0.7637 - val_accuracy: 0.7708 - 277ms/epoch - 4ms/step\n",
      "Epoch 37/500\n",
      "72/72 - 0s - loss: 0.2895 - accuracy: 0.8750 - val_loss: 0.7644 - val_accuracy: 0.7500 - 270ms/epoch - 4ms/step\n",
      "Epoch 38/500\n",
      "72/72 - 0s - loss: 0.2786 - accuracy: 0.8819 - val_loss: 0.6758 - val_accuracy: 0.7812 - 269ms/epoch - 4ms/step\n",
      "Epoch 39/500\n",
      "72/72 - 0s - loss: 0.2680 - accuracy: 0.8854 - val_loss: 0.7663 - val_accuracy: 0.7604 - 272ms/epoch - 4ms/step\n",
      "Epoch 40/500\n",
      "72/72 - 0s - loss: 0.2755 - accuracy: 0.8785 - val_loss: 0.7378 - val_accuracy: 0.7917 - 271ms/epoch - 4ms/step\n",
      "Epoch 41/500\n",
      "72/72 - 0s - loss: 0.2734 - accuracy: 0.8750 - val_loss: 0.7599 - val_accuracy: 0.7917 - 268ms/epoch - 4ms/step\n",
      "Epoch 42/500\n",
      "72/72 - 0s - loss: 0.2859 - accuracy: 0.8785 - val_loss: 0.7698 - val_accuracy: 0.7708 - 266ms/epoch - 4ms/step\n",
      "Epoch 43/500\n",
      "72/72 - 0s - loss: 0.2530 - accuracy: 0.8889 - val_loss: 0.7949 - val_accuracy: 0.7708 - 272ms/epoch - 4ms/step\n",
      "Epoch 44/500\n",
      "72/72 - 0s - loss: 0.2815 - accuracy: 0.8750 - val_loss: 0.7392 - val_accuracy: 0.7917 - 278ms/epoch - 4ms/step\n",
      "Epoch 45/500\n",
      "72/72 - 0s - loss: 0.3385 - accuracy: 0.8611 - val_loss: 0.6624 - val_accuracy: 0.7917 - 265ms/epoch - 4ms/step\n",
      "Epoch 46/500\n",
      "72/72 - 0s - loss: 0.3163 - accuracy: 0.8785 - val_loss: 0.7173 - val_accuracy: 0.7812 - 273ms/epoch - 4ms/step\n",
      "Epoch 47/500\n",
      "72/72 - 0s - loss: 0.3054 - accuracy: 0.8715 - val_loss: 0.8057 - val_accuracy: 0.7708 - 310ms/epoch - 4ms/step\n",
      "Epoch 48/500\n",
      "72/72 - 0s - loss: 0.3081 - accuracy: 0.8785 - val_loss: 0.7652 - val_accuracy: 0.7500 - 295ms/epoch - 4ms/step\n",
      "Epoch 49/500\n",
      "72/72 - 0s - loss: 0.2641 - accuracy: 0.8819 - val_loss: 0.5900 - val_accuracy: 0.8438 - 266ms/epoch - 4ms/step\n",
      "Epoch 50/500\n",
      "72/72 - 0s - loss: 0.2975 - accuracy: 0.8819 - val_loss: 0.5901 - val_accuracy: 0.8333 - 268ms/epoch - 4ms/step\n",
      "Epoch 51/500\n",
      "72/72 - 0s - loss: 0.2983 - accuracy: 0.8785 - val_loss: 0.6591 - val_accuracy: 0.8021 - 269ms/epoch - 4ms/step\n",
      "Epoch 52/500\n",
      "72/72 - 0s - loss: 0.2501 - accuracy: 0.8889 - val_loss: 0.7041 - val_accuracy: 0.8125 - 284ms/epoch - 4ms/step\n",
      "Epoch 53/500\n",
      "72/72 - 0s - loss: 0.2359 - accuracy: 0.9028 - val_loss: 0.6622 - val_accuracy: 0.8021 - 276ms/epoch - 4ms/step\n",
      "Epoch 54/500\n",
      "72/72 - 0s - loss: 0.2405 - accuracy: 0.8958 - val_loss: 0.6589 - val_accuracy: 0.7812 - 268ms/epoch - 4ms/step\n",
      "Epoch 55/500\n",
      "72/72 - 0s - loss: 0.2622 - accuracy: 0.8854 - val_loss: 0.7033 - val_accuracy: 0.7708 - 264ms/epoch - 4ms/step\n",
      "Epoch 56/500\n",
      "72/72 - 0s - loss: 0.2548 - accuracy: 0.8889 - val_loss: 0.6708 - val_accuracy: 0.8125 - 275ms/epoch - 4ms/step\n",
      "Epoch 57/500\n",
      "72/72 - 0s - loss: 0.2575 - accuracy: 0.8889 - val_loss: 0.6643 - val_accuracy: 0.7708 - 277ms/epoch - 4ms/step\n",
      "Epoch 58/500\n",
      "72/72 - 0s - loss: 0.2883 - accuracy: 0.8715 - val_loss: 0.5384 - val_accuracy: 0.8542 - 268ms/epoch - 4ms/step\n",
      "Epoch 59/500\n",
      "72/72 - 0s - loss: 0.2381 - accuracy: 0.8819 - val_loss: 0.6733 - val_accuracy: 0.8021 - 268ms/epoch - 4ms/step\n",
      "Epoch 60/500\n",
      "72/72 - 0s - loss: 0.2148 - accuracy: 0.8924 - val_loss: 0.6381 - val_accuracy: 0.8021 - 278ms/epoch - 4ms/step\n",
      "Epoch 61/500\n",
      "72/72 - 0s - loss: 0.2171 - accuracy: 0.9028 - val_loss: 0.6850 - val_accuracy: 0.7917 - 275ms/epoch - 4ms/step\n",
      "Epoch 62/500\n",
      "72/72 - 0s - loss: 0.2001 - accuracy: 0.9097 - val_loss: 0.6052 - val_accuracy: 0.8125 - 267ms/epoch - 4ms/step\n",
      "Epoch 63/500\n",
      "72/72 - 0s - loss: 0.2217 - accuracy: 0.9062 - val_loss: 0.6439 - val_accuracy: 0.8542 - 269ms/epoch - 4ms/step\n",
      "Epoch 64/500\n",
      "72/72 - 0s - loss: 0.2530 - accuracy: 0.8819 - val_loss: 0.9364 - val_accuracy: 0.7396 - 277ms/epoch - 4ms/step\n",
      "Epoch 65/500\n",
      "72/72 - 0s - loss: 0.2906 - accuracy: 0.8958 - val_loss: 0.5772 - val_accuracy: 0.8438 - 271ms/epoch - 4ms/step\n",
      "Epoch 66/500\n",
      "72/72 - 0s - loss: 0.2648 - accuracy: 0.8889 - val_loss: 0.5468 - val_accuracy: 0.8333 - 271ms/epoch - 4ms/step\n",
      "Epoch 67/500\n",
      "72/72 - 0s - loss: 0.2334 - accuracy: 0.8889 - val_loss: 0.6145 - val_accuracy: 0.8229 - 270ms/epoch - 4ms/step\n",
      "Epoch 68/500\n",
      "72/72 - 0s - loss: 0.2742 - accuracy: 0.8924 - val_loss: 0.5366 - val_accuracy: 0.8229 - 278ms/epoch - 4ms/step\n",
      "Epoch 69/500\n",
      "72/72 - 0s - loss: 0.2277 - accuracy: 0.9062 - val_loss: 0.6341 - val_accuracy: 0.8229 - 270ms/epoch - 4ms/step\n",
      "Epoch 70/500\n",
      "72/72 - 0s - loss: 0.2309 - accuracy: 0.8889 - val_loss: 0.5585 - val_accuracy: 0.8333 - 268ms/epoch - 4ms/step\n",
      "Epoch 71/500\n",
      "72/72 - 0s - loss: 0.2749 - accuracy: 0.8750 - val_loss: 0.5412 - val_accuracy: 0.7812 - 266ms/epoch - 4ms/step\n",
      "Epoch 72/500\n",
      "72/72 - 0s - loss: 0.3122 - accuracy: 0.8785 - val_loss: 0.6058 - val_accuracy: 0.8438 - 301ms/epoch - 4ms/step\n",
      "Epoch 73/500\n",
      "72/72 - 0s - loss: 0.2936 - accuracy: 0.8576 - val_loss: 0.7124 - val_accuracy: 0.7812 - 272ms/epoch - 4ms/step\n",
      "Epoch 74/500\n",
      "72/72 - 0s - loss: 0.2523 - accuracy: 0.8924 - val_loss: 0.5351 - val_accuracy: 0.8438 - 271ms/epoch - 4ms/step\n",
      "Epoch 75/500\n",
      "72/72 - 0s - loss: 0.2071 - accuracy: 0.9097 - val_loss: 0.5174 - val_accuracy: 0.8333 - 281ms/epoch - 4ms/step\n",
      "Epoch 76/500\n",
      "72/72 - 0s - loss: 0.1908 - accuracy: 0.9132 - val_loss: 0.5704 - val_accuracy: 0.8125 - 280ms/epoch - 4ms/step\n",
      "Epoch 77/500\n",
      "72/72 - 0s - loss: 0.2184 - accuracy: 0.9097 - val_loss: 0.5914 - val_accuracy: 0.8125 - 280ms/epoch - 4ms/step\n",
      "Epoch 78/500\n",
      "72/72 - 0s - loss: 0.3266 - accuracy: 0.8611 - val_loss: 0.5940 - val_accuracy: 0.7604 - 271ms/epoch - 4ms/step\n",
      "Epoch 79/500\n",
      "72/72 - 0s - loss: 0.2985 - accuracy: 0.8854 - val_loss: 0.6341 - val_accuracy: 0.6979 - 272ms/epoch - 4ms/step\n",
      "Epoch 80/500\n",
      "72/72 - 0s - loss: 0.2802 - accuracy: 0.8750 - val_loss: 0.6158 - val_accuracy: 0.8021 - 281ms/epoch - 4ms/step\n",
      "Epoch 81/500\n",
      "72/72 - 0s - loss: 0.2445 - accuracy: 0.9097 - val_loss: 0.6568 - val_accuracy: 0.8333 - 269ms/epoch - 4ms/step\n",
      "Epoch 82/500\n",
      "72/72 - 0s - loss: 0.1891 - accuracy: 0.9097 - val_loss: 0.6447 - val_accuracy: 0.8021 - 276ms/epoch - 4ms/step\n",
      "Epoch 83/500\n",
      "72/72 - 0s - loss: 0.1583 - accuracy: 0.9306 - val_loss: 0.6524 - val_accuracy: 0.8125 - 268ms/epoch - 4ms/step\n",
      "Epoch 84/500\n",
      "72/72 - 0s - loss: 0.1558 - accuracy: 0.9340 - val_loss: 0.5622 - val_accuracy: 0.8229 - 281ms/epoch - 4ms/step\n",
      "Epoch 85/500\n",
      "72/72 - 0s - loss: 0.1884 - accuracy: 0.9201 - val_loss: 0.5328 - val_accuracy: 0.8229 - 275ms/epoch - 4ms/step\n",
      "Epoch 86/500\n",
      "72/72 - 0s - loss: 0.2421 - accuracy: 0.8993 - val_loss: 0.6254 - val_accuracy: 0.8021 - 271ms/epoch - 4ms/step\n",
      "Epoch 87/500\n",
      "72/72 - 0s - loss: 0.2664 - accuracy: 0.8889 - val_loss: 0.5567 - val_accuracy: 0.8021 - 276ms/epoch - 4ms/step\n",
      "Epoch 88/500\n",
      "72/72 - 0s - loss: 0.2052 - accuracy: 0.9167 - val_loss: 0.5374 - val_accuracy: 0.8438 - 303ms/epoch - 4ms/step\n",
      "Epoch 89/500\n",
      "72/72 - 0s - loss: 0.1845 - accuracy: 0.9201 - val_loss: 0.6318 - val_accuracy: 0.8333 - 270ms/epoch - 4ms/step\n",
      "Epoch 90/500\n",
      "72/72 - 0s - loss: 0.1618 - accuracy: 0.9271 - val_loss: 0.6473 - val_accuracy: 0.8646 - 275ms/epoch - 4ms/step\n",
      "Epoch 91/500\n",
      "72/72 - 0s - loss: 0.1761 - accuracy: 0.9167 - val_loss: 0.6567 - val_accuracy: 0.8125 - 277ms/epoch - 4ms/step\n",
      "Epoch 92/500\n",
      "72/72 - 0s - loss: 0.2059 - accuracy: 0.9062 - val_loss: 0.5659 - val_accuracy: 0.8125 - 273ms/epoch - 4ms/step\n",
      "Epoch 93/500\n",
      "72/72 - 0s - loss: 0.1768 - accuracy: 0.9201 - val_loss: 0.6585 - val_accuracy: 0.8021 - 275ms/epoch - 4ms/step\n",
      "Epoch 94/500\n",
      "72/72 - 0s - loss: 0.1471 - accuracy: 0.9271 - val_loss: 0.6000 - val_accuracy: 0.8229 - 269ms/epoch - 4ms/step\n",
      "Epoch 95/500\n",
      "72/72 - 0s - loss: 0.1403 - accuracy: 0.9340 - val_loss: 0.5854 - val_accuracy: 0.8542 - 283ms/epoch - 4ms/step\n",
      "Epoch 96/500\n",
      "72/72 - 0s - loss: 0.1519 - accuracy: 0.9375 - val_loss: 0.5412 - val_accuracy: 0.8229 - 265ms/epoch - 4ms/step\n",
      "Epoch 97/500\n",
      "72/72 - 0s - loss: 0.1520 - accuracy: 0.9236 - val_loss: 0.6348 - val_accuracy: 0.8542 - 269ms/epoch - 4ms/step\n",
      "Epoch 98/500\n",
      "72/72 - 0s - loss: 0.1490 - accuracy: 0.9201 - val_loss: 0.5570 - val_accuracy: 0.8333 - 266ms/epoch - 4ms/step\n",
      "Epoch 99/500\n",
      "72/72 - 0s - loss: 0.1613 - accuracy: 0.9306 - val_loss: 0.5547 - val_accuracy: 0.8646 - 276ms/epoch - 4ms/step\n",
      "Epoch 100/500\n",
      "72/72 - 0s - loss: 0.1482 - accuracy: 0.9201 - val_loss: 0.5828 - val_accuracy: 0.8750 - 265ms/epoch - 4ms/step\n",
      "Epoch 101/500\n",
      "72/72 - 0s - loss: 0.1214 - accuracy: 0.9271 - val_loss: 0.5280 - val_accuracy: 0.8854 - 273ms/epoch - 4ms/step\n",
      "Epoch 102/500\n",
      "72/72 - 0s - loss: 0.1238 - accuracy: 0.9306 - val_loss: 0.5900 - val_accuracy: 0.8646 - 260ms/epoch - 4ms/step\n",
      "Epoch 103/500\n",
      "72/72 - 0s - loss: 0.1280 - accuracy: 0.9340 - val_loss: 0.5446 - val_accuracy: 0.8229 - 289ms/epoch - 4ms/step\n",
      "Epoch 104/500\n",
      "72/72 - 0s - loss: 0.1329 - accuracy: 0.9271 - val_loss: 0.5566 - val_accuracy: 0.8542 - 266ms/epoch - 4ms/step\n",
      "Epoch 105/500\n",
      "72/72 - 0s - loss: 0.1160 - accuracy: 0.9306 - val_loss: 0.5880 - val_accuracy: 0.8646 - 265ms/epoch - 4ms/step\n",
      "Epoch 106/500\n",
      "72/72 - 0s - loss: 0.1250 - accuracy: 0.9271 - val_loss: 0.6127 - val_accuracy: 0.8438 - 269ms/epoch - 4ms/step\n",
      "Epoch 107/500\n",
      "72/72 - 0s - loss: 0.1469 - accuracy: 0.9236 - val_loss: 0.5696 - val_accuracy: 0.8333 - 281ms/epoch - 4ms/step\n",
      "Epoch 108/500\n",
      "72/72 - 0s - loss: 0.1385 - accuracy: 0.9306 - val_loss: 0.5710 - val_accuracy: 0.8646 - 270ms/epoch - 4ms/step\n",
      "Epoch 109/500\n",
      "72/72 - 0s - loss: 0.1505 - accuracy: 0.9271 - val_loss: 0.5906 - val_accuracy: 0.8333 - 269ms/epoch - 4ms/step\n",
      "Epoch 110/500\n",
      "72/72 - 0s - loss: 0.1373 - accuracy: 0.9271 - val_loss: 0.5639 - val_accuracy: 0.8229 - 269ms/epoch - 4ms/step\n",
      "Epoch 111/500\n",
      "72/72 - 0s - loss: 0.1376 - accuracy: 0.9271 - val_loss: 0.5059 - val_accuracy: 0.8229 - 294ms/epoch - 4ms/step\n",
      "Epoch 112/500\n",
      "72/72 - 0s - loss: 0.1700 - accuracy: 0.9306 - val_loss: 0.6865 - val_accuracy: 0.8229 - 268ms/epoch - 4ms/step\n",
      "Epoch 113/500\n",
      "72/72 - 0s - loss: 0.1963 - accuracy: 0.9062 - val_loss: 0.5129 - val_accuracy: 0.8438 - 262ms/epoch - 4ms/step\n",
      "Epoch 114/500\n",
      "72/72 - 0s - loss: 0.2281 - accuracy: 0.8993 - val_loss: 0.5375 - val_accuracy: 0.8542 - 263ms/epoch - 4ms/step\n",
      "Epoch 115/500\n",
      "72/72 - 0s - loss: 0.2219 - accuracy: 0.9062 - val_loss: 0.5484 - val_accuracy: 0.8229 - 274ms/epoch - 4ms/step\n",
      "Epoch 116/500\n",
      "72/72 - 0s - loss: 0.1811 - accuracy: 0.9097 - val_loss: 0.7603 - val_accuracy: 0.8646 - 267ms/epoch - 4ms/step\n",
      "Epoch 117/500\n",
      "72/72 - 0s - loss: 0.2847 - accuracy: 0.8715 - val_loss: 0.8940 - val_accuracy: 0.6667 - 272ms/epoch - 4ms/step\n",
      "Epoch 118/500\n",
      "72/72 - 0s - loss: 0.3818 - accuracy: 0.8333 - val_loss: 0.7319 - val_accuracy: 0.8438 - 263ms/epoch - 4ms/step\n",
      "Epoch 119/500\n",
      "72/72 - 0s - loss: 0.3084 - accuracy: 0.8750 - val_loss: 0.5999 - val_accuracy: 0.7917 - 275ms/epoch - 4ms/step\n",
      "Epoch 120/500\n",
      "72/72 - 0s - loss: 0.2235 - accuracy: 0.9028 - val_loss: 0.6747 - val_accuracy: 0.8229 - 279ms/epoch - 4ms/step\n",
      "Epoch 121/500\n",
      "72/72 - 0s - loss: 0.2258 - accuracy: 0.9028 - val_loss: 0.5380 - val_accuracy: 0.8542 - 265ms/epoch - 4ms/step\n",
      "Epoch 122/500\n",
      "72/72 - 0s - loss: 0.1795 - accuracy: 0.9271 - val_loss: 0.7266 - val_accuracy: 0.8333 - 269ms/epoch - 4ms/step\n",
      "Epoch 123/500\n",
      "72/72 - 0s - loss: 0.2172 - accuracy: 0.9028 - val_loss: 0.8451 - val_accuracy: 0.8021 - 283ms/epoch - 4ms/step\n",
      "Epoch 124/500\n",
      "72/72 - 0s - loss: 0.2104 - accuracy: 0.9028 - val_loss: 0.8564 - val_accuracy: 0.7708 - 271ms/epoch - 4ms/step\n",
      "Epoch 125/500\n",
      "72/72 - 0s - loss: 0.1649 - accuracy: 0.9306 - val_loss: 0.7723 - val_accuracy: 0.8125 - 271ms/epoch - 4ms/step\n",
      "Epoch 126/500\n",
      "72/72 - 0s - loss: 0.1388 - accuracy: 0.9340 - val_loss: 0.8213 - val_accuracy: 0.8125 - 261ms/epoch - 4ms/step\n",
      "Epoch 127/500\n",
      "72/72 - 0s - loss: 0.1434 - accuracy: 0.9340 - val_loss: 0.7561 - val_accuracy: 0.8229 - 276ms/epoch - 4ms/step\n",
      "Epoch 128/500\n",
      "72/72 - 0s - loss: 0.1395 - accuracy: 0.9201 - val_loss: 0.7844 - val_accuracy: 0.8125 - 265ms/epoch - 4ms/step\n",
      "Epoch 129/500\n",
      "72/72 - 0s - loss: 0.1579 - accuracy: 0.9236 - val_loss: 0.9641 - val_accuracy: 0.7396 - 362ms/epoch - 5ms/step\n",
      "Epoch 130/500\n",
      "72/72 - 0s - loss: 0.1878 - accuracy: 0.9236 - val_loss: 0.6956 - val_accuracy: 0.8021 - 268ms/epoch - 4ms/step\n",
      "Epoch 131/500\n",
      "72/72 - 0s - loss: 0.1808 - accuracy: 0.9167 - val_loss: 0.7018 - val_accuracy: 0.7812 - 275ms/epoch - 4ms/step\n",
      "Epoch 132/500\n",
      "72/72 - 0s - loss: 0.1676 - accuracy: 0.9340 - val_loss: 0.5013 - val_accuracy: 0.8958 - 267ms/epoch - 4ms/step\n",
      "Epoch 133/500\n",
      "72/72 - 0s - loss: 0.1669 - accuracy: 0.9306 - val_loss: 0.6394 - val_accuracy: 0.8333 - 267ms/epoch - 4ms/step\n",
      "Epoch 134/500\n",
      "72/72 - 0s - loss: 0.1227 - accuracy: 0.9479 - val_loss: 0.5948 - val_accuracy: 0.8958 - 264ms/epoch - 4ms/step\n",
      "Epoch 135/500\n",
      "72/72 - 0s - loss: 0.2109 - accuracy: 0.9201 - val_loss: 0.5581 - val_accuracy: 0.8646 - 276ms/epoch - 4ms/step\n",
      "Epoch 136/500\n",
      "72/72 - 0s - loss: 0.1356 - accuracy: 0.9410 - val_loss: 0.6545 - val_accuracy: 0.8646 - 262ms/epoch - 4ms/step\n",
      "Epoch 137/500\n",
      "72/72 - 0s - loss: 0.1353 - accuracy: 0.9444 - val_loss: 0.7113 - val_accuracy: 0.8125 - 268ms/epoch - 4ms/step\n",
      "Epoch 138/500\n",
      "72/72 - 0s - loss: 0.1078 - accuracy: 0.9549 - val_loss: 0.7236 - val_accuracy: 0.8542 - 257ms/epoch - 4ms/step\n",
      "Epoch 139/500\n",
      "72/72 - 0s - loss: 0.1815 - accuracy: 0.9236 - val_loss: 0.6274 - val_accuracy: 0.8542 - 286ms/epoch - 4ms/step\n",
      "Epoch 140/500\n",
      "72/72 - 0s - loss: 0.1394 - accuracy: 0.9306 - val_loss: 0.8853 - val_accuracy: 0.7917 - 269ms/epoch - 4ms/step\n",
      "Epoch 141/500\n",
      "72/72 - 0s - loss: 0.1726 - accuracy: 0.9132 - val_loss: 0.6528 - val_accuracy: 0.8333 - 270ms/epoch - 4ms/step\n",
      "Epoch 142/500\n",
      "72/72 - 0s - loss: 0.1420 - accuracy: 0.9514 - val_loss: 0.6155 - val_accuracy: 0.8750 - 275ms/epoch - 4ms/step\n",
      "Epoch 143/500\n",
      "72/72 - 0s - loss: 0.1363 - accuracy: 0.9444 - val_loss: 0.7092 - val_accuracy: 0.8229 - 283ms/epoch - 4ms/step\n",
      "Epoch 144/500\n",
      "72/72 - 0s - loss: 0.1356 - accuracy: 0.9479 - val_loss: 0.6931 - val_accuracy: 0.8438 - 275ms/epoch - 4ms/step\n",
      "Epoch 145/500\n",
      "72/72 - 0s - loss: 0.1484 - accuracy: 0.9410 - val_loss: 0.7403 - val_accuracy: 0.8333 - 262ms/epoch - 4ms/step\n",
      "Epoch 146/500\n",
      "72/72 - 0s - loss: 0.1910 - accuracy: 0.9201 - val_loss: 0.7063 - val_accuracy: 0.8125 - 282ms/epoch - 4ms/step\n",
      "Epoch 147/500\n",
      "72/72 - 0s - loss: 0.2269 - accuracy: 0.9167 - val_loss: 0.9378 - val_accuracy: 0.7812 - 295ms/epoch - 4ms/step\n",
      "Epoch 148/500\n",
      "72/72 - 0s - loss: 0.2140 - accuracy: 0.9201 - val_loss: 0.7825 - val_accuracy: 0.8542 - 279ms/epoch - 4ms/step\n",
      "Epoch 149/500\n",
      "72/72 - 0s - loss: 0.1241 - accuracy: 0.9514 - val_loss: 0.7719 - val_accuracy: 0.8750 - 273ms/epoch - 4ms/step\n",
      "Epoch 150/500\n",
      "72/72 - 0s - loss: 0.1798 - accuracy: 0.9306 - val_loss: 1.1090 - val_accuracy: 0.8021 - 310ms/epoch - 4ms/step\n",
      "Epoch 151/500\n",
      "72/72 - 0s - loss: 0.1915 - accuracy: 0.9236 - val_loss: 0.6584 - val_accuracy: 0.8646 - 312ms/epoch - 4ms/step\n",
      "Epoch 152/500\n",
      "72/72 - 0s - loss: 0.1464 - accuracy: 0.9306 - val_loss: 0.7395 - val_accuracy: 0.8438 - 279ms/epoch - 4ms/step\n",
      "Epoch 153/500\n",
      "72/72 - 0s - loss: 0.1361 - accuracy: 0.9479 - val_loss: 0.7845 - val_accuracy: 0.8646 - 318ms/epoch - 4ms/step\n",
      "Epoch 154/500\n",
      "72/72 - 0s - loss: 0.1279 - accuracy: 0.9479 - val_loss: 0.8034 - val_accuracy: 0.8750 - 286ms/epoch - 4ms/step\n",
      "Epoch 155/500\n",
      "72/72 - 0s - loss: 0.1667 - accuracy: 0.9306 - val_loss: 1.0221 - val_accuracy: 0.7917 - 312ms/epoch - 4ms/step\n",
      "Epoch 156/500\n",
      "72/72 - 0s - loss: 0.2303 - accuracy: 0.9167 - val_loss: 1.2121 - val_accuracy: 0.7396 - 336ms/epoch - 5ms/step\n",
      "Epoch 157/500\n",
      "72/72 - 0s - loss: 0.1977 - accuracy: 0.9236 - val_loss: 0.7199 - val_accuracy: 0.8750 - 308ms/epoch - 4ms/step\n",
      "Epoch 158/500\n",
      "72/72 - 0s - loss: 0.1257 - accuracy: 0.9514 - val_loss: 0.7929 - val_accuracy: 0.8646 - 268ms/epoch - 4ms/step\n",
      "Epoch 159/500\n",
      "72/72 - 0s - loss: 0.1436 - accuracy: 0.9410 - val_loss: 0.7605 - val_accuracy: 0.8958 - 278ms/epoch - 4ms/step\n",
      "Epoch 160/500\n",
      "72/72 - 0s - loss: 0.1760 - accuracy: 0.9201 - val_loss: 0.7648 - val_accuracy: 0.8125 - 280ms/epoch - 4ms/step\n",
      "Epoch 161/500\n",
      "72/72 - 0s - loss: 0.2058 - accuracy: 0.9167 - val_loss: 0.8837 - val_accuracy: 0.8750 - 286ms/epoch - 4ms/step\n",
      "Epoch 162/500\n",
      "72/72 - 0s - loss: 0.2130 - accuracy: 0.9132 - val_loss: 0.8157 - val_accuracy: 0.8021 - 287ms/epoch - 4ms/step\n",
      "Epoch 163/500\n",
      "72/72 - 0s - loss: 0.1858 - accuracy: 0.9306 - val_loss: 0.8552 - val_accuracy: 0.8021 - 310ms/epoch - 4ms/step\n",
      "Epoch 164/500\n",
      "72/72 - 0s - loss: 0.2697 - accuracy: 0.8958 - val_loss: 0.6462 - val_accuracy: 0.8021 - 269ms/epoch - 4ms/step\n",
      "Epoch 165/500\n",
      "72/72 - 0s - loss: 0.2548 - accuracy: 0.9201 - val_loss: 0.6244 - val_accuracy: 0.8438 - 277ms/epoch - 4ms/step\n",
      "Epoch 166/500\n",
      "72/72 - 0s - loss: 0.1853 - accuracy: 0.9097 - val_loss: 0.8045 - val_accuracy: 0.8542 - 277ms/epoch - 4ms/step\n",
      "Epoch 167/500\n",
      "72/72 - 0s - loss: 0.1647 - accuracy: 0.9410 - val_loss: 0.7350 - val_accuracy: 0.8646 - 275ms/epoch - 4ms/step\n",
      "Epoch 168/500\n",
      "72/72 - 0s - loss: 0.2010 - accuracy: 0.9132 - val_loss: 0.6969 - val_accuracy: 0.8438 - 270ms/epoch - 4ms/step\n",
      "Epoch 169/500\n",
      "72/72 - 0s - loss: 0.1709 - accuracy: 0.9271 - val_loss: 0.8410 - val_accuracy: 0.8229 - 301ms/epoch - 4ms/step\n",
      "Epoch 170/500\n",
      "72/72 - 0s - loss: 0.1345 - accuracy: 0.9444 - val_loss: 0.7310 - val_accuracy: 0.8958 - 281ms/epoch - 4ms/step\n",
      "Epoch 171/500\n",
      "72/72 - 0s - loss: 0.1462 - accuracy: 0.9375 - val_loss: 0.7706 - val_accuracy: 0.8542 - 274ms/epoch - 4ms/step\n",
      "Epoch 172/500\n",
      "72/72 - 0s - loss: 0.1614 - accuracy: 0.9410 - val_loss: 0.7999 - val_accuracy: 0.8229 - 273ms/epoch - 4ms/step\n",
      "Epoch 173/500\n",
      "72/72 - 0s - loss: 0.1552 - accuracy: 0.9375 - val_loss: 0.8315 - val_accuracy: 0.8854 - 283ms/epoch - 4ms/step\n",
      "Epoch 174/500\n",
      "72/72 - 0s - loss: 0.1407 - accuracy: 0.9444 - val_loss: 0.8328 - val_accuracy: 0.8333 - 303ms/epoch - 4ms/step\n",
      "Epoch 175/500\n",
      "72/72 - 0s - loss: 0.1171 - accuracy: 0.9549 - val_loss: 0.9097 - val_accuracy: 0.8542 - 314ms/epoch - 4ms/step\n",
      "Epoch 176/500\n",
      "72/72 - 0s - loss: 0.1078 - accuracy: 0.9549 - val_loss: 0.9311 - val_accuracy: 0.8125 - 305ms/epoch - 4ms/step\n",
      "Epoch 177/500\n",
      "72/72 - 0s - loss: 0.1216 - accuracy: 0.9444 - val_loss: 0.9186 - val_accuracy: 0.8542 - 278ms/epoch - 4ms/step\n",
      "Epoch 178/500\n",
      "72/72 - 0s - loss: 0.2314 - accuracy: 0.9236 - val_loss: 0.8664 - val_accuracy: 0.8542 - 288ms/epoch - 4ms/step\n",
      "Epoch 179/500\n",
      "72/72 - 0s - loss: 0.2097 - accuracy: 0.9167 - val_loss: 0.7845 - val_accuracy: 0.8438 - 305ms/epoch - 4ms/step\n",
      "Epoch 180/500\n",
      "72/72 - 0s - loss: 0.1664 - accuracy: 0.9444 - val_loss: 0.8239 - val_accuracy: 0.8333 - 292ms/epoch - 4ms/step\n",
      "Epoch 181/500\n",
      "72/72 - 0s - loss: 0.1455 - accuracy: 0.9444 - val_loss: 0.7608 - val_accuracy: 0.8333 - 273ms/epoch - 4ms/step\n",
      "Epoch 182/500\n",
      "72/72 - 0s - loss: 0.1613 - accuracy: 0.9375 - val_loss: 0.8336 - val_accuracy: 0.8229 - 303ms/epoch - 4ms/step\n",
      "Epoch 183/500\n",
      "72/72 - 0s - loss: 0.1403 - accuracy: 0.9340 - val_loss: 0.9431 - val_accuracy: 0.8125 - 278ms/epoch - 4ms/step\n",
      "Epoch 184/500\n",
      "72/72 - 0s - loss: 0.1957 - accuracy: 0.9201 - val_loss: 0.8532 - val_accuracy: 0.8021 - 304ms/epoch - 4ms/step\n",
      "Epoch 185/500\n",
      "72/72 - 0s - loss: 0.1100 - accuracy: 0.9549 - val_loss: 0.8855 - val_accuracy: 0.8229 - 271ms/epoch - 4ms/step\n",
      "Epoch 186/500\n",
      "72/72 - 0s - loss: 0.1059 - accuracy: 0.9479 - val_loss: 0.9351 - val_accuracy: 0.8438 - 299ms/epoch - 4ms/step\n",
      "Epoch 187/500\n",
      "72/72 - 0s - loss: 0.1445 - accuracy: 0.9271 - val_loss: 0.8090 - val_accuracy: 0.8646 - 288ms/epoch - 4ms/step\n",
      "Epoch 188/500\n",
      "72/72 - 0s - loss: 0.1346 - accuracy: 0.9410 - val_loss: 0.8103 - val_accuracy: 0.8021 - 333ms/epoch - 5ms/step\n",
      "Epoch 189/500\n",
      "72/72 - 0s - loss: 0.1305 - accuracy: 0.9340 - val_loss: 0.8318 - val_accuracy: 0.8646 - 290ms/epoch - 4ms/step\n",
      "Epoch 190/500\n",
      "72/72 - 0s - loss: 0.1819 - accuracy: 0.9271 - val_loss: 0.8805 - val_accuracy: 0.7812 - 279ms/epoch - 4ms/step\n",
      "Epoch 191/500\n",
      "72/72 - 0s - loss: 0.1334 - accuracy: 0.9410 - val_loss: 0.7930 - val_accuracy: 0.8438 - 285ms/epoch - 4ms/step\n",
      "Epoch 192/500\n",
      "72/72 - 0s - loss: 0.1269 - accuracy: 0.9375 - val_loss: 0.8975 - val_accuracy: 0.8542 - 279ms/epoch - 4ms/step\n",
      "Epoch 193/500\n",
      "72/72 - 0s - loss: 0.1339 - accuracy: 0.9444 - val_loss: 0.8446 - val_accuracy: 0.8229 - 281ms/epoch - 4ms/step\n",
      "Epoch 194/500\n",
      "72/72 - 0s - loss: 0.1318 - accuracy: 0.9479 - val_loss: 0.7917 - val_accuracy: 0.8646 - 277ms/epoch - 4ms/step\n",
      "Epoch 195/500\n",
      "72/72 - 0s - loss: 0.1174 - accuracy: 0.9340 - val_loss: 0.7991 - val_accuracy: 0.8646 - 285ms/epoch - 4ms/step\n",
      "Epoch 196/500\n",
      "72/72 - 0s - loss: 0.1061 - accuracy: 0.9479 - val_loss: 0.8982 - val_accuracy: 0.8333 - 279ms/epoch - 4ms/step\n",
      "Epoch 197/500\n",
      "72/72 - 0s - loss: 0.1267 - accuracy: 0.9444 - val_loss: 1.0593 - val_accuracy: 0.8542 - 296ms/epoch - 4ms/step\n",
      "Epoch 198/500\n",
      "72/72 - 0s - loss: 0.1122 - accuracy: 0.9479 - val_loss: 0.9450 - val_accuracy: 0.8542 - 283ms/epoch - 4ms/step\n",
      "Epoch 199/500\n",
      "72/72 - 0s - loss: 0.1444 - accuracy: 0.9271 - val_loss: 0.8128 - val_accuracy: 0.8750 - 280ms/epoch - 4ms/step\n",
      "Epoch 200/500\n",
      "72/72 - 0s - loss: 0.1450 - accuracy: 0.9340 - val_loss: 0.7524 - val_accuracy: 0.8229 - 267ms/epoch - 4ms/step\n",
      "Epoch 201/500\n",
      "72/72 - 0s - loss: 0.1691 - accuracy: 0.9306 - val_loss: 1.0154 - val_accuracy: 0.8125 - 267ms/epoch - 4ms/step\n",
      "Epoch 202/500\n",
      "72/72 - 0s - loss: 0.1089 - accuracy: 0.9479 - val_loss: 0.9079 - val_accuracy: 0.8438 - 270ms/epoch - 4ms/step\n",
      "Epoch 203/500\n",
      "72/72 - 0s - loss: 0.1284 - accuracy: 0.9271 - val_loss: 0.9496 - val_accuracy: 0.8229 - 283ms/epoch - 4ms/step\n",
      "Epoch 204/500\n",
      "72/72 - 0s - loss: 0.1264 - accuracy: 0.9444 - val_loss: 0.6152 - val_accuracy: 0.8854 - 335ms/epoch - 5ms/step\n",
      "Epoch 205/500\n",
      "72/72 - 0s - loss: 0.1265 - accuracy: 0.9444 - val_loss: 0.7941 - val_accuracy: 0.7708 - 337ms/epoch - 5ms/step\n",
      "Epoch 206/500\n",
      "72/72 - 0s - loss: 0.1080 - accuracy: 0.9375 - val_loss: 0.8000 - val_accuracy: 0.8542 - 284ms/epoch - 4ms/step\n",
      "Epoch 207/500\n",
      "72/72 - 0s - loss: 0.1078 - accuracy: 0.9410 - val_loss: 0.7642 - val_accuracy: 0.8646 - 309ms/epoch - 4ms/step\n",
      "Epoch 208/500\n",
      "72/72 - 0s - loss: 0.1029 - accuracy: 0.9444 - val_loss: 0.7590 - val_accuracy: 0.8333 - 276ms/epoch - 4ms/step\n",
      "Epoch 209/500\n",
      "72/72 - 0s - loss: 0.1088 - accuracy: 0.9375 - val_loss: 0.7243 - val_accuracy: 0.8125 - 346ms/epoch - 5ms/step\n",
      "Epoch 210/500\n",
      "72/72 - 0s - loss: 0.1311 - accuracy: 0.9410 - val_loss: 0.9511 - val_accuracy: 0.8229 - 334ms/epoch - 5ms/step\n",
      "Epoch 211/500\n",
      "72/72 - 0s - loss: 0.1501 - accuracy: 0.9306 - val_loss: 0.9451 - val_accuracy: 0.8229 - 363ms/epoch - 5ms/step\n",
      "Epoch 212/500\n",
      "72/72 - 0s - loss: 0.1619 - accuracy: 0.9340 - val_loss: 0.6638 - val_accuracy: 0.8542 - 341ms/epoch - 5ms/step\n",
      "Epoch 213/500\n",
      "72/72 - 0s - loss: 0.2493 - accuracy: 0.9306 - val_loss: 0.9628 - val_accuracy: 0.7708 - 305ms/epoch - 4ms/step\n",
      "Epoch 214/500\n",
      "72/72 - 0s - loss: 0.1491 - accuracy: 0.9340 - val_loss: 0.5600 - val_accuracy: 0.8854 - 300ms/epoch - 4ms/step\n",
      "Epoch 215/500\n",
      "72/72 - 0s - loss: 0.1264 - accuracy: 0.9306 - val_loss: 0.7621 - val_accuracy: 0.8125 - 272ms/epoch - 4ms/step\n",
      "Epoch 216/500\n",
      "72/72 - 0s - loss: 0.1294 - accuracy: 0.9375 - val_loss: 0.6295 - val_accuracy: 0.8438 - 303ms/epoch - 4ms/step\n",
      "Epoch 217/500\n",
      "72/72 - 0s - loss: 0.1157 - accuracy: 0.9479 - val_loss: 0.6947 - val_accuracy: 0.8229 - 389ms/epoch - 5ms/step\n",
      "Epoch 218/500\n",
      "72/72 - 0s - loss: 0.1290 - accuracy: 0.9375 - val_loss: 1.0163 - val_accuracy: 0.7812 - 291ms/epoch - 4ms/step\n",
      "Epoch 219/500\n",
      "72/72 - 0s - loss: 0.2038 - accuracy: 0.9340 - val_loss: 0.6034 - val_accuracy: 0.8542 - 310ms/epoch - 4ms/step\n",
      "Epoch 220/500\n",
      "72/72 - 0s - loss: 0.1158 - accuracy: 0.9410 - val_loss: 0.6379 - val_accuracy: 0.8542 - 360ms/epoch - 5ms/step\n",
      "Epoch 221/500\n",
      "72/72 - 0s - loss: 0.0983 - accuracy: 0.9444 - val_loss: 0.6282 - val_accuracy: 0.8125 - 342ms/epoch - 5ms/step\n",
      "Epoch 222/500\n",
      "72/72 - 0s - loss: 0.0950 - accuracy: 0.9549 - val_loss: 0.6669 - val_accuracy: 0.8542 - 276ms/epoch - 4ms/step\n",
      "Epoch 223/500\n",
      "72/72 - 0s - loss: 0.0864 - accuracy: 0.9514 - val_loss: 0.7431 - val_accuracy: 0.7812 - 313ms/epoch - 4ms/step\n",
      "Epoch 224/500\n",
      "72/72 - 0s - loss: 0.1094 - accuracy: 0.9479 - val_loss: 0.7773 - val_accuracy: 0.7708 - 293ms/epoch - 4ms/step\n",
      "Epoch 225/500\n",
      "72/72 - 0s - loss: 0.1338 - accuracy: 0.9410 - val_loss: 0.7207 - val_accuracy: 0.8333 - 281ms/epoch - 4ms/step\n",
      "Epoch 226/500\n",
      "72/72 - 0s - loss: 0.2011 - accuracy: 0.9097 - val_loss: 0.7177 - val_accuracy: 0.8438 - 297ms/epoch - 4ms/step\n",
      "Epoch 227/500\n",
      "72/72 - 0s - loss: 0.1544 - accuracy: 0.9306 - val_loss: 0.7863 - val_accuracy: 0.8229 - 313ms/epoch - 4ms/step\n",
      "Epoch 228/500\n",
      "72/72 - 0s - loss: 0.1529 - accuracy: 0.9201 - val_loss: 0.7804 - val_accuracy: 0.8542 - 281ms/epoch - 4ms/step\n",
      "Epoch 229/500\n",
      "72/72 - 0s - loss: 0.1084 - accuracy: 0.9583 - val_loss: 0.6576 - val_accuracy: 0.8438 - 308ms/epoch - 4ms/step\n",
      "Epoch 230/500\n",
      "72/72 - 0s - loss: 0.1198 - accuracy: 0.9549 - val_loss: 0.6876 - val_accuracy: 0.8229 - 280ms/epoch - 4ms/step\n",
      "Epoch 231/500\n",
      "72/72 - 0s - loss: 0.0813 - accuracy: 0.9653 - val_loss: 0.6637 - val_accuracy: 0.8646 - 298ms/epoch - 4ms/step\n",
      "Epoch 232/500\n",
      "72/72 - 0s - loss: 0.0991 - accuracy: 0.9514 - val_loss: 0.7335 - val_accuracy: 0.8333 - 286ms/epoch - 4ms/step\n",
      "Epoch 233/500\n",
      "72/72 - 0s - loss: 0.1022 - accuracy: 0.9514 - val_loss: 0.7174 - val_accuracy: 0.8438 - 280ms/epoch - 4ms/step\n",
      "Epoch 234/500\n",
      "72/72 - 0s - loss: 0.1094 - accuracy: 0.9375 - val_loss: 0.7423 - val_accuracy: 0.8333 - 296ms/epoch - 4ms/step\n",
      "Epoch 235/500\n",
      "72/72 - 0s - loss: 0.1250 - accuracy: 0.9410 - val_loss: 0.6063 - val_accuracy: 0.8438 - 274ms/epoch - 4ms/step\n",
      "Epoch 236/500\n",
      "72/72 - 0s - loss: 0.1018 - accuracy: 0.9375 - val_loss: 0.8205 - val_accuracy: 0.8438 - 286ms/epoch - 4ms/step\n",
      "Epoch 237/500\n",
      "72/72 - 0s - loss: 0.0968 - accuracy: 0.9514 - val_loss: 0.8760 - val_accuracy: 0.8333 - 275ms/epoch - 4ms/step\n",
      "Epoch 238/500\n",
      "72/72 - 0s - loss: 0.1681 - accuracy: 0.9340 - val_loss: 0.9869 - val_accuracy: 0.8333 - 292ms/epoch - 4ms/step\n",
      "Epoch 239/500\n",
      "72/72 - 0s - loss: 0.1601 - accuracy: 0.9340 - val_loss: 0.9535 - val_accuracy: 0.8125 - 274ms/epoch - 4ms/step\n",
      "Epoch 240/500\n",
      "72/72 - 0s - loss: 0.1865 - accuracy: 0.9340 - val_loss: 1.1745 - val_accuracy: 0.7396 - 334ms/epoch - 5ms/step\n",
      "Epoch 241/500\n",
      "72/72 - 0s - loss: 0.3093 - accuracy: 0.8889 - val_loss: 1.0816 - val_accuracy: 0.7292 - 293ms/epoch - 4ms/step\n",
      "Epoch 242/500\n",
      "72/72 - 0s - loss: 0.3189 - accuracy: 0.8889 - val_loss: 0.9596 - val_accuracy: 0.7812 - 302ms/epoch - 4ms/step\n",
      "Epoch 243/500\n",
      "72/72 - 1s - loss: 0.2760 - accuracy: 0.8889 - val_loss: 0.9260 - val_accuracy: 0.8229 - 507ms/epoch - 7ms/step\n",
      "Epoch 244/500\n",
      "72/72 - 0s - loss: 0.2696 - accuracy: 0.8889 - val_loss: 0.6897 - val_accuracy: 0.8542 - 258ms/epoch - 4ms/step\n",
      "Epoch 245/500\n",
      "72/72 - 0s - loss: 0.1824 - accuracy: 0.9271 - val_loss: 1.0897 - val_accuracy: 0.7812 - 236ms/epoch - 3ms/step\n",
      "Epoch 246/500\n",
      "72/72 - 0s - loss: 0.2059 - accuracy: 0.9132 - val_loss: 1.1257 - val_accuracy: 0.8333 - 251ms/epoch - 3ms/step\n",
      "Epoch 247/500\n",
      "72/72 - 0s - loss: 0.2052 - accuracy: 0.9375 - val_loss: 0.5878 - val_accuracy: 0.8854 - 269ms/epoch - 4ms/step\n",
      "Epoch 248/500\n",
      "72/72 - 0s - loss: 0.1057 - accuracy: 0.9688 - val_loss: 0.7822 - val_accuracy: 0.8542 - 237ms/epoch - 3ms/step\n",
      "Epoch 249/500\n",
      "72/72 - 0s - loss: 0.0788 - accuracy: 0.9688 - val_loss: 0.7623 - val_accuracy: 0.8438 - 251ms/epoch - 3ms/step\n",
      "Epoch 250/500\n",
      "72/72 - 0s - loss: 0.1347 - accuracy: 0.9514 - val_loss: 0.7446 - val_accuracy: 0.8229 - 310ms/epoch - 4ms/step\n",
      "Epoch 251/500\n",
      "72/72 - 0s - loss: 0.1820 - accuracy: 0.9306 - val_loss: 0.7561 - val_accuracy: 0.8229 - 375ms/epoch - 5ms/step\n",
      "Epoch 252/500\n",
      "72/72 - 0s - loss: 0.1624 - accuracy: 0.9271 - val_loss: 0.7789 - val_accuracy: 0.8333 - 321ms/epoch - 4ms/step\n",
      "Epoch 253/500\n",
      "72/72 - 0s - loss: 0.1200 - accuracy: 0.9583 - val_loss: 0.6818 - val_accuracy: 0.8750 - 273ms/epoch - 4ms/step\n",
      "Epoch 254/500\n",
      "72/72 - 0s - loss: 0.0774 - accuracy: 0.9688 - val_loss: 0.6430 - val_accuracy: 0.8750 - 295ms/epoch - 4ms/step\n",
      "Epoch 255/500\n",
      "72/72 - 0s - loss: 0.0803 - accuracy: 0.9722 - val_loss: 0.6154 - val_accuracy: 0.8646 - 276ms/epoch - 4ms/step\n",
      "Epoch 256/500\n",
      "72/72 - 0s - loss: 0.1071 - accuracy: 0.9549 - val_loss: 0.7608 - val_accuracy: 0.8229 - 277ms/epoch - 4ms/step\n",
      "Epoch 257/500\n",
      "72/72 - 0s - loss: 0.1222 - accuracy: 0.9479 - val_loss: 0.7045 - val_accuracy: 0.8125 - 310ms/epoch - 4ms/step\n",
      "Epoch 258/500\n",
      "72/72 - 0s - loss: 0.2263 - accuracy: 0.9236 - val_loss: 0.7791 - val_accuracy: 0.8021 - 275ms/epoch - 4ms/step\n",
      "Epoch 259/500\n",
      "72/72 - 0s - loss: 0.1582 - accuracy: 0.9271 - val_loss: 0.7523 - val_accuracy: 0.8646 - 266ms/epoch - 4ms/step\n",
      "Epoch 260/500\n",
      "72/72 - 0s - loss: 0.2903 - accuracy: 0.8854 - val_loss: 0.7170 - val_accuracy: 0.8021 - 282ms/epoch - 4ms/step\n",
      "Epoch 261/500\n",
      "72/72 - 0s - loss: 0.2208 - accuracy: 0.9062 - val_loss: 0.7272 - val_accuracy: 0.8333 - 270ms/epoch - 4ms/step\n",
      "Epoch 262/500\n",
      "72/72 - 0s - loss: 0.1886 - accuracy: 0.9167 - val_loss: 0.6549 - val_accuracy: 0.8750 - 270ms/epoch - 4ms/step\n",
      "Epoch 263/500\n",
      "72/72 - 0s - loss: 0.2612 - accuracy: 0.9028 - val_loss: 0.6288 - val_accuracy: 0.8542 - 264ms/epoch - 4ms/step\n",
      "Epoch 264/500\n",
      "72/72 - 0s - loss: 0.1484 - accuracy: 0.9375 - val_loss: 0.5888 - val_accuracy: 0.8333 - 276ms/epoch - 4ms/step\n",
      "Epoch 265/500\n",
      "72/72 - 0s - loss: 0.1209 - accuracy: 0.9479 - val_loss: 0.5426 - val_accuracy: 0.9271 - 269ms/epoch - 4ms/step\n",
      "Epoch 266/500\n",
      "72/72 - 0s - loss: 0.1102 - accuracy: 0.9514 - val_loss: 0.6572 - val_accuracy: 0.8646 - 264ms/epoch - 4ms/step\n",
      "Epoch 267/500\n",
      "72/72 - 0s - loss: 0.1092 - accuracy: 0.9583 - val_loss: 0.6734 - val_accuracy: 0.8646 - 271ms/epoch - 4ms/step\n",
      "Epoch 268/500\n",
      "72/72 - 0s - loss: 0.0797 - accuracy: 0.9653 - val_loss: 0.6547 - val_accuracy: 0.8854 - 277ms/epoch - 4ms/step\n",
      "Epoch 269/500\n",
      "72/72 - 0s - loss: 0.0952 - accuracy: 0.9583 - val_loss: 0.6928 - val_accuracy: 0.8750 - 265ms/epoch - 4ms/step\n",
      "Epoch 270/500\n",
      "72/72 - 0s - loss: 0.0986 - accuracy: 0.9583 - val_loss: 0.8487 - val_accuracy: 0.8646 - 267ms/epoch - 4ms/step\n",
      "Epoch 271/500\n",
      "72/72 - 0s - loss: 0.1717 - accuracy: 0.9375 - val_loss: 0.6868 - val_accuracy: 0.8229 - 288ms/epoch - 4ms/step\n",
      "Epoch 272/500\n",
      "72/72 - 0s - loss: 0.1328 - accuracy: 0.9444 - val_loss: 0.6525 - val_accuracy: 0.8125 - 283ms/epoch - 4ms/step\n",
      "Epoch 273/500\n",
      "72/72 - 0s - loss: 0.1662 - accuracy: 0.9479 - val_loss: 0.8990 - val_accuracy: 0.8021 - 271ms/epoch - 4ms/step\n",
      "Epoch 274/500\n",
      "72/72 - 0s - loss: 0.1199 - accuracy: 0.9583 - val_loss: 0.7193 - val_accuracy: 0.8125 - 273ms/epoch - 4ms/step\n",
      "Epoch 275/500\n",
      "72/72 - 0s - loss: 0.1188 - accuracy: 0.9514 - val_loss: 0.7653 - val_accuracy: 0.8750 - 261ms/epoch - 4ms/step\n",
      "Epoch 276/500\n",
      "72/72 - 0s - loss: 0.0972 - accuracy: 0.9618 - val_loss: 0.7741 - val_accuracy: 0.8229 - 297ms/epoch - 4ms/step\n",
      "Epoch 277/500\n",
      "72/72 - 0s - loss: 0.0862 - accuracy: 0.9583 - val_loss: 0.6389 - val_accuracy: 0.8542 - 272ms/epoch - 4ms/step\n",
      "Epoch 278/500\n",
      "72/72 - 0s - loss: 0.1038 - accuracy: 0.9479 - val_loss: 0.7656 - val_accuracy: 0.8229 - 279ms/epoch - 4ms/step\n",
      "Epoch 279/500\n",
      "72/72 - 0s - loss: 0.1080 - accuracy: 0.9479 - val_loss: 0.7578 - val_accuracy: 0.8229 - 279ms/epoch - 4ms/step\n",
      "Epoch 280/500\n",
      "72/72 - 0s - loss: 0.1715 - accuracy: 0.9410 - val_loss: 0.7077 - val_accuracy: 0.8438 - 277ms/epoch - 4ms/step\n",
      "Epoch 281/500\n",
      "72/72 - 0s - loss: 0.0978 - accuracy: 0.9479 - val_loss: 0.7984 - val_accuracy: 0.8125 - 273ms/epoch - 4ms/step\n",
      "Epoch 282/500\n",
      "72/72 - 0s - loss: 0.0840 - accuracy: 0.9653 - val_loss: 0.7645 - val_accuracy: 0.8229 - 269ms/epoch - 4ms/step\n",
      "Epoch 283/500\n",
      "72/72 - 0s - loss: 0.0808 - accuracy: 0.9618 - val_loss: 0.7608 - val_accuracy: 0.8438 - 276ms/epoch - 4ms/step\n",
      "Epoch 284/500\n",
      "72/72 - 0s - loss: 0.0811 - accuracy: 0.9653 - val_loss: 0.8142 - val_accuracy: 0.8438 - 274ms/epoch - 4ms/step\n",
      "Epoch 285/500\n",
      "72/72 - 0s - loss: 0.0827 - accuracy: 0.9653 - val_loss: 0.9533 - val_accuracy: 0.8438 - 273ms/epoch - 4ms/step\n",
      "Epoch 286/500\n",
      "72/72 - 0s - loss: 0.1463 - accuracy: 0.9375 - val_loss: 1.0915 - val_accuracy: 0.8333 - 263ms/epoch - 4ms/step\n",
      "Epoch 287/500\n",
      "72/72 - 0s - loss: 0.1467 - accuracy: 0.9479 - val_loss: 0.7206 - val_accuracy: 0.8958 - 270ms/epoch - 4ms/step\n",
      "Epoch 288/500\n",
      "72/72 - 0s - loss: 0.1702 - accuracy: 0.9306 - val_loss: 0.9105 - val_accuracy: 0.7812 - 267ms/epoch - 4ms/step\n",
      "Epoch 289/500\n",
      "72/72 - 0s - loss: 0.1122 - accuracy: 0.9514 - val_loss: 0.5467 - val_accuracy: 0.8854 - 262ms/epoch - 4ms/step\n",
      "Epoch 290/500\n",
      "72/72 - 0s - loss: 0.1566 - accuracy: 0.9410 - val_loss: 0.7986 - val_accuracy: 0.7604 - 262ms/epoch - 4ms/step\n",
      "Epoch 291/500\n",
      "72/72 - 0s - loss: 0.1415 - accuracy: 0.9375 - val_loss: 0.7651 - val_accuracy: 0.8021 - 271ms/epoch - 4ms/step\n",
      "Epoch 292/500\n",
      "72/72 - 0s - loss: 0.2005 - accuracy: 0.9201 - val_loss: 0.7574 - val_accuracy: 0.8229 - 269ms/epoch - 4ms/step\n",
      "Epoch 293/500\n",
      "72/72 - 0s - loss: 0.2249 - accuracy: 0.9097 - val_loss: 0.8005 - val_accuracy: 0.8229 - 265ms/epoch - 4ms/step\n",
      "Epoch 294/500\n",
      "72/72 - 0s - loss: 0.1865 - accuracy: 0.9306 - val_loss: 0.9278 - val_accuracy: 0.8125 - 263ms/epoch - 4ms/step\n",
      "Epoch 295/500\n",
      "72/72 - 0s - loss: 0.1325 - accuracy: 0.9444 - val_loss: 0.8947 - val_accuracy: 0.8438 - 290ms/epoch - 4ms/step\n",
      "Epoch 296/500\n",
      "72/72 - 0s - loss: 0.1181 - accuracy: 0.9444 - val_loss: 0.6618 - val_accuracy: 0.8229 - 272ms/epoch - 4ms/step\n",
      "Epoch 297/500\n",
      "72/72 - 0s - loss: 0.1254 - accuracy: 0.9410 - val_loss: 0.8641 - val_accuracy: 0.7708 - 266ms/epoch - 4ms/step\n",
      "Epoch 298/500\n",
      "72/72 - 0s - loss: 0.1089 - accuracy: 0.9618 - val_loss: 0.7273 - val_accuracy: 0.8125 - 265ms/epoch - 4ms/step\n",
      "Epoch 299/500\n",
      "72/72 - 0s - loss: 0.0989 - accuracy: 0.9549 - val_loss: 0.7712 - val_accuracy: 0.8333 - 358ms/epoch - 5ms/step\n",
      "Epoch 300/500\n",
      "72/72 - 0s - loss: 0.0885 - accuracy: 0.9618 - val_loss: 0.9420 - val_accuracy: 0.7812 - 269ms/epoch - 4ms/step\n",
      "Epoch 301/500\n",
      "72/72 - 0s - loss: 0.0916 - accuracy: 0.9583 - val_loss: 0.8026 - val_accuracy: 0.8125 - 264ms/epoch - 4ms/step\n",
      "Epoch 302/500\n",
      "72/72 - 0s - loss: 0.0697 - accuracy: 0.9653 - val_loss: 0.7785 - val_accuracy: 0.8438 - 268ms/epoch - 4ms/step\n",
      "Epoch 303/500\n",
      "72/72 - 0s - loss: 0.0751 - accuracy: 0.9688 - val_loss: 0.7506 - val_accuracy: 0.8646 - 271ms/epoch - 4ms/step\n",
      "Epoch 304/500\n",
      "72/72 - 0s - loss: 0.0718 - accuracy: 0.9688 - val_loss: 0.8116 - val_accuracy: 0.8750 - 270ms/epoch - 4ms/step\n",
      "Epoch 305/500\n",
      "72/72 - 0s - loss: 0.0728 - accuracy: 0.9618 - val_loss: 0.8990 - val_accuracy: 0.8750 - 260ms/epoch - 4ms/step\n",
      "Epoch 306/500\n",
      "72/72 - 0s - loss: 0.0982 - accuracy: 0.9514 - val_loss: 1.1235 - val_accuracy: 0.8854 - 267ms/epoch - 4ms/step\n",
      "Epoch 307/500\n",
      "72/72 - 0s - loss: 0.1379 - accuracy: 0.9549 - val_loss: 0.9402 - val_accuracy: 0.8333 - 277ms/epoch - 4ms/step\n",
      "Epoch 308/500\n",
      "72/72 - 0s - loss: 0.2508 - accuracy: 0.9097 - val_loss: 0.7488 - val_accuracy: 0.8333 - 271ms/epoch - 4ms/step\n",
      "Epoch 309/500\n",
      "72/72 - 0s - loss: 0.2478 - accuracy: 0.9132 - val_loss: 0.8320 - val_accuracy: 0.8333 - 278ms/epoch - 4ms/step\n",
      "Epoch 310/500\n",
      "72/72 - 0s - loss: 0.3142 - accuracy: 0.8854 - val_loss: 0.9167 - val_accuracy: 0.7604 - 265ms/epoch - 4ms/step\n",
      "Epoch 311/500\n",
      "72/72 - 0s - loss: 0.2601 - accuracy: 0.9062 - val_loss: 0.8472 - val_accuracy: 0.7500 - 279ms/epoch - 4ms/step\n",
      "Epoch 312/500\n",
      "72/72 - 0s - loss: 0.1935 - accuracy: 0.9444 - val_loss: 0.5652 - val_accuracy: 0.8750 - 272ms/epoch - 4ms/step\n",
      "Epoch 313/500\n",
      "72/72 - 0s - loss: 0.1751 - accuracy: 0.9340 - val_loss: 0.6429 - val_accuracy: 0.8542 - 268ms/epoch - 4ms/step\n",
      "Epoch 314/500\n",
      "72/72 - 0s - loss: 0.1668 - accuracy: 0.9375 - val_loss: 0.6284 - val_accuracy: 0.8646 - 265ms/epoch - 4ms/step\n",
      "Epoch 315/500\n",
      "72/72 - 0s - loss: 0.2252 - accuracy: 0.9236 - val_loss: 0.5702 - val_accuracy: 0.8750 - 272ms/epoch - 4ms/step\n",
      "Epoch 316/500\n",
      "72/72 - 0s - loss: 0.1645 - accuracy: 0.9306 - val_loss: 0.4669 - val_accuracy: 0.9167 - 286ms/epoch - 4ms/step\n",
      "Epoch 317/500\n",
      "72/72 - 0s - loss: 0.1194 - accuracy: 0.9375 - val_loss: 0.6997 - val_accuracy: 0.8438 - 265ms/epoch - 4ms/step\n",
      "Epoch 318/500\n",
      "72/72 - 0s - loss: 0.1156 - accuracy: 0.9549 - val_loss: 0.5691 - val_accuracy: 0.9062 - 261ms/epoch - 4ms/step\n",
      "Epoch 319/500\n",
      "72/72 - 0s - loss: 0.1587 - accuracy: 0.9375 - val_loss: 0.6380 - val_accuracy: 0.8333 - 273ms/epoch - 4ms/step\n",
      "Epoch 320/500\n",
      "72/72 - 0s - loss: 0.1164 - accuracy: 0.9514 - val_loss: 0.7472 - val_accuracy: 0.8021 - 262ms/epoch - 4ms/step\n",
      "Epoch 321/500\n",
      "72/72 - 0s - loss: 0.1369 - accuracy: 0.9514 - val_loss: 0.8284 - val_accuracy: 0.8542 - 269ms/epoch - 4ms/step\n",
      "Epoch 322/500\n",
      "72/72 - 0s - loss: 0.0960 - accuracy: 0.9444 - val_loss: 0.6950 - val_accuracy: 0.8750 - 264ms/epoch - 4ms/step\n",
      "Epoch 323/500\n",
      "72/72 - 0s - loss: 0.1086 - accuracy: 0.9618 - val_loss: 0.7692 - val_accuracy: 0.8854 - 268ms/epoch - 4ms/step\n",
      "Epoch 324/500\n",
      "72/72 - 0s - loss: 0.1003 - accuracy: 0.9618 - val_loss: 0.7248 - val_accuracy: 0.8854 - 266ms/epoch - 4ms/step\n",
      "Epoch 325/500\n",
      "72/72 - 0s - loss: 0.0815 - accuracy: 0.9583 - val_loss: 0.7862 - val_accuracy: 0.8333 - 267ms/epoch - 4ms/step\n",
      "Epoch 326/500\n",
      "72/72 - 0s - loss: 0.1014 - accuracy: 0.9618 - val_loss: 0.7819 - val_accuracy: 0.8646 - 271ms/epoch - 4ms/step\n",
      "Epoch 327/500\n",
      "72/72 - 0s - loss: 0.0764 - accuracy: 0.9618 - val_loss: 0.7729 - val_accuracy: 0.8958 - 280ms/epoch - 4ms/step\n",
      "Epoch 328/500\n",
      "72/72 - 0s - loss: 0.0709 - accuracy: 0.9583 - val_loss: 0.8624 - val_accuracy: 0.8229 - 267ms/epoch - 4ms/step\n",
      "Epoch 329/500\n",
      "72/72 - 0s - loss: 0.0759 - accuracy: 0.9583 - val_loss: 0.7850 - val_accuracy: 0.8646 - 272ms/epoch - 4ms/step\n",
      "Epoch 330/500\n",
      "72/72 - 0s - loss: 0.0727 - accuracy: 0.9549 - val_loss: 0.8843 - val_accuracy: 0.8333 - 264ms/epoch - 4ms/step\n",
      "Epoch 331/500\n",
      "72/72 - 0s - loss: 0.0719 - accuracy: 0.9583 - val_loss: 0.7881 - val_accuracy: 0.8438 - 282ms/epoch - 4ms/step\n",
      "Epoch 332/500\n",
      "72/72 - 0s - loss: 0.0753 - accuracy: 0.9618 - val_loss: 0.8526 - val_accuracy: 0.8750 - 259ms/epoch - 4ms/step\n",
      "Epoch 333/500\n",
      "72/72 - 0s - loss: 0.0710 - accuracy: 0.9583 - val_loss: 0.8335 - val_accuracy: 0.8646 - 274ms/epoch - 4ms/step\n",
      "Epoch 334/500\n",
      "72/72 - 0s - loss: 0.0759 - accuracy: 0.9583 - val_loss: 0.8338 - val_accuracy: 0.8333 - 265ms/epoch - 4ms/step\n",
      "Epoch 335/500\n",
      "72/72 - 0s - loss: 0.0635 - accuracy: 0.9722 - val_loss: 0.9145 - val_accuracy: 0.8333 - 274ms/epoch - 4ms/step\n",
      "Epoch 336/500\n",
      "72/72 - 0s - loss: 0.0644 - accuracy: 0.9688 - val_loss: 0.8583 - val_accuracy: 0.8854 - 260ms/epoch - 4ms/step\n",
      "Epoch 337/500\n",
      "72/72 - 0s - loss: 0.0667 - accuracy: 0.9653 - val_loss: 0.8451 - val_accuracy: 0.8854 - 286ms/epoch - 4ms/step\n",
      "Epoch 338/500\n",
      "72/72 - 0s - loss: 0.0625 - accuracy: 0.9583 - val_loss: 0.8200 - val_accuracy: 0.8854 - 269ms/epoch - 4ms/step\n",
      "Epoch 339/500\n",
      "72/72 - 0s - loss: 0.0598 - accuracy: 0.9618 - val_loss: 0.8817 - val_accuracy: 0.8854 - 280ms/epoch - 4ms/step\n",
      "Epoch 340/500\n",
      "72/72 - 0s - loss: 0.0739 - accuracy: 0.9583 - val_loss: 0.8290 - val_accuracy: 0.8750 - 268ms/epoch - 4ms/step\n",
      "Epoch 341/500\n",
      "72/72 - 0s - loss: 0.1733 - accuracy: 0.9271 - val_loss: 0.8261 - val_accuracy: 0.8542 - 283ms/epoch - 4ms/step\n",
      "Epoch 342/500\n",
      "72/72 - 0s - loss: 0.1318 - accuracy: 0.9514 - val_loss: 0.6636 - val_accuracy: 0.8750 - 263ms/epoch - 4ms/step\n",
      "Epoch 343/500\n",
      "72/72 - 0s - loss: 0.1860 - accuracy: 0.9271 - val_loss: 0.7688 - val_accuracy: 0.8646 - 274ms/epoch - 4ms/step\n",
      "Epoch 344/500\n",
      "72/72 - 0s - loss: 0.2245 - accuracy: 0.9306 - val_loss: 0.7694 - val_accuracy: 0.8646 - 267ms/epoch - 4ms/step\n",
      "Epoch 345/500\n",
      "72/72 - 0s - loss: 0.2209 - accuracy: 0.9236 - val_loss: 0.7147 - val_accuracy: 0.8542 - 268ms/epoch - 4ms/step\n",
      "Epoch 346/500\n",
      "72/72 - 0s - loss: 0.3120 - accuracy: 0.8819 - val_loss: 0.7327 - val_accuracy: 0.8646 - 268ms/epoch - 4ms/step\n",
      "Epoch 347/500\n",
      "72/72 - 0s - loss: 0.1652 - accuracy: 0.9236 - val_loss: 0.8558 - val_accuracy: 0.8646 - 277ms/epoch - 4ms/step\n",
      "Epoch 348/500\n",
      "72/72 - 0s - loss: 0.1808 - accuracy: 0.9340 - val_loss: 0.7408 - val_accuracy: 0.8125 - 297ms/epoch - 4ms/step\n",
      "Epoch 349/500\n",
      "72/72 - 0s - loss: 0.1201 - accuracy: 0.9514 - val_loss: 0.8870 - val_accuracy: 0.8229 - 272ms/epoch - 4ms/step\n",
      "Epoch 350/500\n",
      "72/72 - 0s - loss: 0.2197 - accuracy: 0.9201 - val_loss: 0.6771 - val_accuracy: 0.8646 - 276ms/epoch - 4ms/step\n",
      "Epoch 351/500\n",
      "72/72 - 0s - loss: 0.1676 - accuracy: 0.9340 - val_loss: 0.6679 - val_accuracy: 0.8438 - 270ms/epoch - 4ms/step\n",
      "Epoch 352/500\n",
      "72/72 - 0s - loss: 0.1473 - accuracy: 0.9375 - val_loss: 0.8924 - val_accuracy: 0.8438 - 267ms/epoch - 4ms/step\n",
      "Epoch 353/500\n",
      "72/72 - 0s - loss: 0.1422 - accuracy: 0.9444 - val_loss: 0.6769 - val_accuracy: 0.8750 - 282ms/epoch - 4ms/step\n",
      "Epoch 354/500\n",
      "72/72 - 0s - loss: 0.0950 - accuracy: 0.9549 - val_loss: 0.5694 - val_accuracy: 0.8854 - 271ms/epoch - 4ms/step\n",
      "Epoch 355/500\n",
      "72/72 - 0s - loss: 0.0674 - accuracy: 0.9722 - val_loss: 0.5593 - val_accuracy: 0.9062 - 284ms/epoch - 4ms/step\n",
      "Epoch 356/500\n",
      "72/72 - 0s - loss: 0.0786 - accuracy: 0.9583 - val_loss: 0.7385 - val_accuracy: 0.8542 - 258ms/epoch - 4ms/step\n",
      "Epoch 357/500\n",
      "72/72 - 0s - loss: 0.0998 - accuracy: 0.9618 - val_loss: 0.6171 - val_accuracy: 0.9062 - 291ms/epoch - 4ms/step\n",
      "Epoch 358/500\n",
      "72/72 - 0s - loss: 0.0791 - accuracy: 0.9653 - val_loss: 0.5865 - val_accuracy: 0.8854 - 266ms/epoch - 4ms/step\n",
      "Epoch 359/500\n",
      "72/72 - 0s - loss: 0.0662 - accuracy: 0.9618 - val_loss: 0.6565 - val_accuracy: 0.8958 - 277ms/epoch - 4ms/step\n",
      "Epoch 360/500\n",
      "72/72 - 0s - loss: 0.0635 - accuracy: 0.9583 - val_loss: 0.6685 - val_accuracy: 0.8958 - 265ms/epoch - 4ms/step\n",
      "Epoch 361/500\n",
      "72/72 - 0s - loss: 0.0511 - accuracy: 0.9688 - val_loss: 0.6853 - val_accuracy: 0.8958 - 269ms/epoch - 4ms/step\n",
      "Epoch 362/500\n",
      "72/72 - 0s - loss: 0.0553 - accuracy: 0.9618 - val_loss: 0.6477 - val_accuracy: 0.8854 - 267ms/epoch - 4ms/step\n",
      "Epoch 363/500\n",
      "72/72 - 0s - loss: 0.0704 - accuracy: 0.9618 - val_loss: 0.6213 - val_accuracy: 0.8646 - 274ms/epoch - 4ms/step\n",
      "Epoch 364/500\n",
      "72/72 - 0s - loss: 0.0701 - accuracy: 0.9618 - val_loss: 0.6719 - val_accuracy: 0.8542 - 267ms/epoch - 4ms/step\n",
      "Epoch 365/500\n",
      "72/72 - 0s - loss: 0.0588 - accuracy: 0.9653 - val_loss: 0.6836 - val_accuracy: 0.8542 - 267ms/epoch - 4ms/step\n",
      "Epoch 366/500\n",
      "72/72 - 0s - loss: 0.0560 - accuracy: 0.9722 - val_loss: 0.6592 - val_accuracy: 0.9167 - 262ms/epoch - 4ms/step\n",
      "Epoch 367/500\n",
      "72/72 - 0s - loss: 0.0501 - accuracy: 0.9688 - val_loss: 0.7457 - val_accuracy: 0.8958 - 319ms/epoch - 4ms/step\n",
      "Epoch 368/500\n",
      "72/72 - 0s - loss: 0.0532 - accuracy: 0.9688 - val_loss: 0.7159 - val_accuracy: 0.8438 - 290ms/epoch - 4ms/step\n",
      "Epoch 369/500\n",
      "72/72 - 0s - loss: 0.0556 - accuracy: 0.9722 - val_loss: 0.7024 - val_accuracy: 0.8958 - 269ms/epoch - 4ms/step\n",
      "Epoch 370/500\n",
      "72/72 - 0s - loss: 0.0614 - accuracy: 0.9549 - val_loss: 0.6830 - val_accuracy: 0.9062 - 281ms/epoch - 4ms/step\n",
      "Epoch 371/500\n",
      "72/72 - 0s - loss: 0.0777 - accuracy: 0.9583 - val_loss: 0.8708 - val_accuracy: 0.8438 - 275ms/epoch - 4ms/step\n",
      "Epoch 372/500\n",
      "72/72 - 0s - loss: 0.2584 - accuracy: 0.8993 - val_loss: 0.8084 - val_accuracy: 0.8750 - 267ms/epoch - 4ms/step\n",
      "Epoch 373/500\n",
      "72/72 - 0s - loss: 0.2712 - accuracy: 0.8854 - val_loss: 1.0446 - val_accuracy: 0.7917 - 266ms/epoch - 4ms/step\n",
      "Epoch 374/500\n",
      "72/72 - 0s - loss: 0.2787 - accuracy: 0.9132 - val_loss: 0.7175 - val_accuracy: 0.8854 - 266ms/epoch - 4ms/step\n",
      "Epoch 375/500\n",
      "72/72 - 0s - loss: 0.1629 - accuracy: 0.9444 - val_loss: 0.9099 - val_accuracy: 0.8646 - 275ms/epoch - 4ms/step\n",
      "Epoch 376/500\n",
      "72/72 - 0s - loss: 0.1193 - accuracy: 0.9549 - val_loss: 0.7578 - val_accuracy: 0.8646 - 291ms/epoch - 4ms/step\n",
      "Epoch 377/500\n",
      "72/72 - 0s - loss: 0.0921 - accuracy: 0.9549 - val_loss: 0.7603 - val_accuracy: 0.8750 - 264ms/epoch - 4ms/step\n",
      "Epoch 378/500\n",
      "72/72 - 0s - loss: 0.0687 - accuracy: 0.9653 - val_loss: 0.7204 - val_accuracy: 0.8958 - 269ms/epoch - 4ms/step\n",
      "Epoch 379/500\n",
      "72/72 - 0s - loss: 0.0641 - accuracy: 0.9688 - val_loss: 0.7631 - val_accuracy: 0.8854 - 268ms/epoch - 4ms/step\n",
      "Epoch 380/500\n",
      "72/72 - 0s - loss: 0.0903 - accuracy: 0.9549 - val_loss: 0.7290 - val_accuracy: 0.8854 - 265ms/epoch - 4ms/step\n",
      "Epoch 381/500\n",
      "72/72 - 0s - loss: 0.1467 - accuracy: 0.9271 - val_loss: 1.1000 - val_accuracy: 0.8021 - 264ms/epoch - 4ms/step\n",
      "Epoch 382/500\n",
      "72/72 - 0s - loss: 0.1264 - accuracy: 0.9514 - val_loss: 0.6397 - val_accuracy: 0.8750 - 266ms/epoch - 4ms/step\n",
      "Epoch 383/500\n",
      "72/72 - 0s - loss: 0.1021 - accuracy: 0.9514 - val_loss: 0.7726 - val_accuracy: 0.8542 - 271ms/epoch - 4ms/step\n",
      "Epoch 384/500\n",
      "72/72 - 0s - loss: 0.0991 - accuracy: 0.9688 - val_loss: 0.7736 - val_accuracy: 0.8646 - 263ms/epoch - 4ms/step\n",
      "Epoch 385/500\n",
      "72/72 - 0s - loss: 0.0989 - accuracy: 0.9653 - val_loss: 0.7174 - val_accuracy: 0.9062 - 268ms/epoch - 4ms/step\n",
      "Epoch 386/500\n",
      "72/72 - 0s - loss: 0.0644 - accuracy: 0.9688 - val_loss: 0.7446 - val_accuracy: 0.8958 - 267ms/epoch - 4ms/step\n",
      "Epoch 387/500\n",
      "72/72 - 0s - loss: 0.0699 - accuracy: 0.9688 - val_loss: 0.8696 - val_accuracy: 0.8438 - 273ms/epoch - 4ms/step\n",
      "Epoch 388/500\n",
      "72/72 - 0s - loss: 0.0787 - accuracy: 0.9583 - val_loss: 0.8276 - val_accuracy: 0.8750 - 261ms/epoch - 4ms/step\n",
      "Epoch 389/500\n",
      "72/72 - 0s - loss: 0.1585 - accuracy: 0.9444 - val_loss: 0.8973 - val_accuracy: 0.7604 - 259ms/epoch - 4ms/step\n",
      "Epoch 390/500\n",
      "72/72 - 0s - loss: 0.2053 - accuracy: 0.9340 - val_loss: 0.9885 - val_accuracy: 0.8229 - 271ms/epoch - 4ms/step\n",
      "Epoch 391/500\n",
      "72/72 - 0s - loss: 0.2032 - accuracy: 0.9097 - val_loss: 0.8448 - val_accuracy: 0.8438 - 296ms/epoch - 4ms/step\n",
      "Epoch 392/500\n",
      "72/72 - 0s - loss: 0.1683 - accuracy: 0.9236 - val_loss: 0.9029 - val_accuracy: 0.8229 - 264ms/epoch - 4ms/step\n",
      "Epoch 393/500\n",
      "72/72 - 0s - loss: 0.1088 - accuracy: 0.9583 - val_loss: 0.8945 - val_accuracy: 0.8646 - 282ms/epoch - 4ms/step\n",
      "Epoch 394/500\n",
      "72/72 - 0s - loss: 0.1678 - accuracy: 0.9410 - val_loss: 0.8770 - val_accuracy: 0.7917 - 270ms/epoch - 4ms/step\n",
      "Epoch 395/500\n",
      "72/72 - 0s - loss: 0.1534 - accuracy: 0.9410 - val_loss: 0.6307 - val_accuracy: 0.8438 - 273ms/epoch - 4ms/step\n",
      "Epoch 396/500\n",
      "72/72 - 0s - loss: 0.0843 - accuracy: 0.9653 - val_loss: 0.7738 - val_accuracy: 0.8854 - 300ms/epoch - 4ms/step\n",
      "Epoch 397/500\n",
      "72/72 - 0s - loss: 0.0926 - accuracy: 0.9514 - val_loss: 0.7920 - val_accuracy: 0.8542 - 264ms/epoch - 4ms/step\n",
      "Epoch 398/500\n",
      "72/72 - 0s - loss: 0.0818 - accuracy: 0.9583 - val_loss: 0.8171 - val_accuracy: 0.8854 - 263ms/epoch - 4ms/step\n",
      "Epoch 399/500\n",
      "72/72 - 0s - loss: 0.1169 - accuracy: 0.9410 - val_loss: 1.1483 - val_accuracy: 0.7604 - 277ms/epoch - 4ms/step\n",
      "Epoch 400/500\n",
      "72/72 - 0s - loss: 0.0904 - accuracy: 0.9549 - val_loss: 0.9479 - val_accuracy: 0.8438 - 265ms/epoch - 4ms/step\n",
      "Epoch 401/500\n",
      "72/72 - 0s - loss: 0.1259 - accuracy: 0.9444 - val_loss: 0.9978 - val_accuracy: 0.7812 - 272ms/epoch - 4ms/step\n",
      "Epoch 402/500\n",
      "72/72 - 0s - loss: 0.1064 - accuracy: 0.9549 - val_loss: 0.9081 - val_accuracy: 0.8646 - 263ms/epoch - 4ms/step\n",
      "Epoch 403/500\n",
      "72/72 - 0s - loss: 0.0994 - accuracy: 0.9444 - val_loss: 0.9246 - val_accuracy: 0.8542 - 279ms/epoch - 4ms/step\n",
      "Epoch 404/500\n",
      "72/72 - 0s - loss: 0.0592 - accuracy: 0.9653 - val_loss: 0.9815 - val_accuracy: 0.8646 - 268ms/epoch - 4ms/step\n",
      "Epoch 405/500\n",
      "72/72 - 0s - loss: 0.0752 - accuracy: 0.9549 - val_loss: 1.0873 - val_accuracy: 0.8125 - 268ms/epoch - 4ms/step\n",
      "Epoch 406/500\n",
      "72/72 - 0s - loss: 0.1271 - accuracy: 0.9479 - val_loss: 1.5429 - val_accuracy: 0.7188 - 267ms/epoch - 4ms/step\n",
      "Epoch 407/500\n",
      "72/72 - 0s - loss: 0.1148 - accuracy: 0.9583 - val_loss: 1.1607 - val_accuracy: 0.8125 - 274ms/epoch - 4ms/step\n",
      "Epoch 408/500\n",
      "72/72 - 0s - loss: 0.0670 - accuracy: 0.9618 - val_loss: 1.1226 - val_accuracy: 0.8542 - 263ms/epoch - 4ms/step\n",
      "Epoch 409/500\n",
      "72/72 - 0s - loss: 0.1031 - accuracy: 0.9444 - val_loss: 1.1198 - val_accuracy: 0.8542 - 278ms/epoch - 4ms/step\n",
      "Epoch 410/500\n",
      "72/72 - 0s - loss: 0.0638 - accuracy: 0.9722 - val_loss: 1.0962 - val_accuracy: 0.8542 - 264ms/epoch - 4ms/step\n",
      "Epoch 411/500\n",
      "72/72 - 0s - loss: 0.0679 - accuracy: 0.9583 - val_loss: 1.1583 - val_accuracy: 0.7708 - 276ms/epoch - 4ms/step\n",
      "Epoch 412/500\n",
      "72/72 - 0s - loss: 0.0599 - accuracy: 0.9722 - val_loss: 1.0421 - val_accuracy: 0.8646 - 282ms/epoch - 4ms/step\n",
      "Epoch 413/500\n",
      "72/72 - 0s - loss: 0.0695 - accuracy: 0.9583 - val_loss: 1.0683 - val_accuracy: 0.8750 - 267ms/epoch - 4ms/step\n",
      "Epoch 414/500\n",
      "72/72 - 0s - loss: 0.1194 - accuracy: 0.9410 - val_loss: 1.0810 - val_accuracy: 0.8542 - 266ms/epoch - 4ms/step\n",
      "Epoch 415/500\n",
      "72/72 - 0s - loss: 0.1869 - accuracy: 0.9410 - val_loss: 1.2249 - val_accuracy: 0.8333 - 283ms/epoch - 4ms/step\n",
      "Epoch 416/500\n",
      "72/72 - 0s - loss: 0.1309 - accuracy: 0.9583 - val_loss: 1.0702 - val_accuracy: 0.8229 - 274ms/epoch - 4ms/step\n",
      "Epoch 417/500\n",
      "72/72 - 0s - loss: 0.1590 - accuracy: 0.9549 - val_loss: 0.9409 - val_accuracy: 0.8438 - 269ms/epoch - 4ms/step\n",
      "Epoch 418/500\n",
      "72/72 - 0s - loss: 0.1709 - accuracy: 0.9306 - val_loss: 0.8145 - val_accuracy: 0.8333 - 267ms/epoch - 4ms/step\n",
      "Epoch 419/500\n",
      "72/72 - 0s - loss: 0.2175 - accuracy: 0.9306 - val_loss: 0.7654 - val_accuracy: 0.8542 - 277ms/epoch - 4ms/step\n",
      "Epoch 420/500\n",
      "72/72 - 0s - loss: 0.1021 - accuracy: 0.9549 - val_loss: 0.7869 - val_accuracy: 0.8750 - 268ms/epoch - 4ms/step\n",
      "Epoch 421/500\n",
      "72/72 - 0s - loss: 0.0661 - accuracy: 0.9722 - val_loss: 0.8456 - val_accuracy: 0.8646 - 276ms/epoch - 4ms/step\n",
      "Epoch 422/500\n",
      "72/72 - 0s - loss: 0.0573 - accuracy: 0.9688 - val_loss: 0.8440 - val_accuracy: 0.8750 - 277ms/epoch - 4ms/step\n",
      "Epoch 423/500\n",
      "72/72 - 0s - loss: 0.0543 - accuracy: 0.9653 - val_loss: 0.9064 - val_accuracy: 0.8854 - 271ms/epoch - 4ms/step\n",
      "Epoch 424/500\n",
      "72/72 - 0s - loss: 0.0400 - accuracy: 0.9792 - val_loss: 0.8503 - val_accuracy: 0.9062 - 271ms/epoch - 4ms/step\n",
      "Epoch 425/500\n",
      "72/72 - 0s - loss: 0.1143 - accuracy: 0.9549 - val_loss: 1.1098 - val_accuracy: 0.7917 - 271ms/epoch - 4ms/step\n",
      "Epoch 426/500\n",
      "72/72 - 0s - loss: 0.0944 - accuracy: 0.9618 - val_loss: 0.9676 - val_accuracy: 0.8542 - 276ms/epoch - 4ms/step\n",
      "Epoch 427/500\n",
      "72/72 - 0s - loss: 0.1636 - accuracy: 0.9444 - val_loss: 1.1561 - val_accuracy: 0.8021 - 273ms/epoch - 4ms/step\n",
      "Epoch 428/500\n",
      "72/72 - 0s - loss: 0.0751 - accuracy: 0.9653 - val_loss: 0.9838 - val_accuracy: 0.8333 - 288ms/epoch - 4ms/step\n",
      "Epoch 429/500\n",
      "72/72 - 0s - loss: 0.0664 - accuracy: 0.9653 - val_loss: 0.9565 - val_accuracy: 0.8750 - 268ms/epoch - 4ms/step\n",
      "Epoch 430/500\n",
      "72/72 - 0s - loss: 0.0679 - accuracy: 0.9722 - val_loss: 0.9952 - val_accuracy: 0.8229 - 271ms/epoch - 4ms/step\n",
      "Epoch 431/500\n",
      "72/72 - 0s - loss: 0.0612 - accuracy: 0.9688 - val_loss: 0.9504 - val_accuracy: 0.9062 - 267ms/epoch - 4ms/step\n",
      "Epoch 432/500\n",
      "72/72 - 0s - loss: 0.0531 - accuracy: 0.9757 - val_loss: 0.9881 - val_accuracy: 0.8854 - 271ms/epoch - 4ms/step\n",
      "Epoch 433/500\n",
      "72/72 - 0s - loss: 0.0512 - accuracy: 0.9653 - val_loss: 1.0171 - val_accuracy: 0.8750 - 262ms/epoch - 4ms/step\n",
      "Epoch 434/500\n",
      "72/72 - 0s - loss: 0.1205 - accuracy: 0.9583 - val_loss: 1.2619 - val_accuracy: 0.7708 - 270ms/epoch - 4ms/step\n",
      "Epoch 435/500\n",
      "72/72 - 0s - loss: 0.1086 - accuracy: 0.9549 - val_loss: 0.9986 - val_accuracy: 0.8333 - 267ms/epoch - 4ms/step\n",
      "Epoch 436/500\n",
      "72/72 - 0s - loss: 0.0992 - accuracy: 0.9479 - val_loss: 1.0597 - val_accuracy: 0.8542 - 262ms/epoch - 4ms/step\n",
      "Epoch 437/500\n",
      "72/72 - 0s - loss: 0.0901 - accuracy: 0.9479 - val_loss: 0.8963 - val_accuracy: 0.8750 - 266ms/epoch - 4ms/step\n",
      "Epoch 438/500\n",
      "72/72 - 0s - loss: 0.0990 - accuracy: 0.9479 - val_loss: 0.8440 - val_accuracy: 0.8646 - 268ms/epoch - 4ms/step\n",
      "Epoch 439/500\n",
      "72/72 - 0s - loss: 0.1640 - accuracy: 0.9479 - val_loss: 0.7885 - val_accuracy: 0.8125 - 266ms/epoch - 4ms/step\n",
      "Epoch 440/500\n",
      "72/72 - 0s - loss: 0.1026 - accuracy: 0.9479 - val_loss: 1.0532 - val_accuracy: 0.8229 - 285ms/epoch - 4ms/step\n",
      "Epoch 441/500\n",
      "72/72 - 0s - loss: 0.1217 - accuracy: 0.9444 - val_loss: 0.7601 - val_accuracy: 0.8646 - 265ms/epoch - 4ms/step\n",
      "Epoch 442/500\n",
      "72/72 - 0s - loss: 0.1428 - accuracy: 0.9340 - val_loss: 0.7133 - val_accuracy: 0.7917 - 369ms/epoch - 5ms/step\n",
      "Epoch 443/500\n",
      "72/72 - 0s - loss: 0.0969 - accuracy: 0.9688 - val_loss: 0.8435 - val_accuracy: 0.8542 - 265ms/epoch - 4ms/step\n",
      "Epoch 444/500\n",
      "72/72 - 0s - loss: 0.0684 - accuracy: 0.9583 - val_loss: 0.9962 - val_accuracy: 0.8542 - 282ms/epoch - 4ms/step\n",
      "Epoch 445/500\n",
      "72/72 - 0s - loss: 0.0554 - accuracy: 0.9688 - val_loss: 1.1300 - val_accuracy: 0.8750 - 276ms/epoch - 4ms/step\n",
      "Epoch 446/500\n",
      "72/72 - 0s - loss: 0.0430 - accuracy: 0.9722 - val_loss: 1.0740 - val_accuracy: 0.8750 - 269ms/epoch - 4ms/step\n",
      "Epoch 447/500\n",
      "72/72 - 0s - loss: 0.0776 - accuracy: 0.9688 - val_loss: 1.1331 - val_accuracy: 0.8750 - 269ms/epoch - 4ms/step\n",
      "Epoch 448/500\n",
      "72/72 - 0s - loss: 0.0566 - accuracy: 0.9688 - val_loss: 1.0216 - val_accuracy: 0.9167 - 264ms/epoch - 4ms/step\n",
      "Epoch 449/500\n",
      "72/72 - 0s - loss: 0.0460 - accuracy: 0.9722 - val_loss: 1.0291 - val_accuracy: 0.9062 - 263ms/epoch - 4ms/step\n",
      "Epoch 450/500\n",
      "72/72 - 0s - loss: 0.0531 - accuracy: 0.9722 - val_loss: 0.9396 - val_accuracy: 0.9062 - 280ms/epoch - 4ms/step\n",
      "Epoch 451/500\n",
      "72/72 - 0s - loss: 0.0472 - accuracy: 0.9792 - val_loss: 0.9890 - val_accuracy: 0.8854 - 266ms/epoch - 4ms/step\n",
      "Epoch 452/500\n",
      "72/72 - 0s - loss: 0.0394 - accuracy: 0.9757 - val_loss: 1.0127 - val_accuracy: 0.9062 - 261ms/epoch - 4ms/step\n",
      "Epoch 453/500\n",
      "72/72 - 0s - loss: 0.0416 - accuracy: 0.9722 - val_loss: 1.0905 - val_accuracy: 0.8958 - 277ms/epoch - 4ms/step\n",
      "Epoch 454/500\n",
      "72/72 - 0s - loss: 0.0376 - accuracy: 0.9792 - val_loss: 1.0894 - val_accuracy: 0.8958 - 268ms/epoch - 4ms/step\n",
      "Epoch 455/500\n",
      "72/72 - 0s - loss: 0.0393 - accuracy: 0.9722 - val_loss: 1.1493 - val_accuracy: 0.8958 - 265ms/epoch - 4ms/step\n",
      "Epoch 456/500\n",
      "72/72 - 0s - loss: 0.0467 - accuracy: 0.9722 - val_loss: 1.1169 - val_accuracy: 0.8750 - 277ms/epoch - 4ms/step\n",
      "Epoch 457/500\n",
      "72/72 - 0s - loss: 0.0426 - accuracy: 0.9688 - val_loss: 1.1570 - val_accuracy: 0.8750 - 262ms/epoch - 4ms/step\n",
      "Epoch 458/500\n",
      "72/72 - 0s - loss: 0.0377 - accuracy: 0.9792 - val_loss: 1.1619 - val_accuracy: 0.8958 - 278ms/epoch - 4ms/step\n",
      "Epoch 459/500\n",
      "72/72 - 0s - loss: 0.0450 - accuracy: 0.9688 - val_loss: 1.1642 - val_accuracy: 0.8750 - 264ms/epoch - 4ms/step\n",
      "Epoch 460/500\n",
      "72/72 - 0s - loss: 0.0362 - accuracy: 0.9792 - val_loss: 1.1063 - val_accuracy: 0.8750 - 265ms/epoch - 4ms/step\n",
      "Epoch 461/500\n",
      "72/72 - 0s - loss: 0.0467 - accuracy: 0.9722 - val_loss: 1.2269 - val_accuracy: 0.8646 - 283ms/epoch - 4ms/step\n",
      "Epoch 462/500\n",
      "72/72 - 0s - loss: 0.0830 - accuracy: 0.9583 - val_loss: 1.3271 - val_accuracy: 0.8542 - 278ms/epoch - 4ms/step\n",
      "Epoch 463/500\n",
      "72/72 - 0s - loss: 0.3323 - accuracy: 0.9132 - val_loss: 1.0813 - val_accuracy: 0.8646 - 277ms/epoch - 4ms/step\n",
      "Epoch 464/500\n",
      "72/72 - 0s - loss: 0.1826 - accuracy: 0.9375 - val_loss: 0.7556 - val_accuracy: 0.8646 - 269ms/epoch - 4ms/step\n",
      "Epoch 465/500\n",
      "72/72 - 0s - loss: 0.1840 - accuracy: 0.9236 - val_loss: 0.9361 - val_accuracy: 0.8438 - 264ms/epoch - 4ms/step\n",
      "Epoch 466/500\n",
      "72/72 - 0s - loss: 0.1768 - accuracy: 0.9271 - val_loss: 0.8273 - val_accuracy: 0.8229 - 279ms/epoch - 4ms/step\n",
      "Epoch 467/500\n",
      "72/72 - 0s - loss: 0.1005 - accuracy: 0.9549 - val_loss: 1.1125 - val_accuracy: 0.7917 - 263ms/epoch - 4ms/step\n",
      "Epoch 468/500\n",
      "72/72 - 0s - loss: 0.1526 - accuracy: 0.9549 - val_loss: 1.0746 - val_accuracy: 0.8542 - 268ms/epoch - 4ms/step\n",
      "Epoch 469/500\n",
      "72/72 - 0s - loss: 0.1394 - accuracy: 0.9375 - val_loss: 1.0717 - val_accuracy: 0.7917 - 264ms/epoch - 4ms/step\n",
      "Epoch 470/500\n",
      "72/72 - 0s - loss: 0.1005 - accuracy: 0.9514 - val_loss: 1.0441 - val_accuracy: 0.8750 - 275ms/epoch - 4ms/step\n",
      "Epoch 471/500\n",
      "72/72 - 0s - loss: 0.1080 - accuracy: 0.9549 - val_loss: 1.0957 - val_accuracy: 0.8021 - 296ms/epoch - 4ms/step\n",
      "Epoch 472/500\n",
      "72/72 - 0s - loss: 0.0831 - accuracy: 0.9618 - val_loss: 1.0598 - val_accuracy: 0.8646 - 328ms/epoch - 5ms/step\n",
      "Epoch 473/500\n",
      "72/72 - 0s - loss: 0.0617 - accuracy: 0.9653 - val_loss: 1.2063 - val_accuracy: 0.7812 - 301ms/epoch - 4ms/step\n",
      "Epoch 474/500\n",
      "72/72 - 0s - loss: 0.0653 - accuracy: 0.9757 - val_loss: 1.1643 - val_accuracy: 0.8438 - 268ms/epoch - 4ms/step\n",
      "Epoch 475/500\n",
      "72/72 - 0s - loss: 0.0423 - accuracy: 0.9722 - val_loss: 1.1971 - val_accuracy: 0.8542 - 276ms/epoch - 4ms/step\n",
      "Epoch 476/500\n",
      "72/72 - 0s - loss: 0.1065 - accuracy: 0.9618 - val_loss: 1.1005 - val_accuracy: 0.8646 - 289ms/epoch - 4ms/step\n",
      "Epoch 477/500\n",
      "72/72 - 0s - loss: 0.0911 - accuracy: 0.9583 - val_loss: 1.0346 - val_accuracy: 0.8438 - 322ms/epoch - 4ms/step\n",
      "Epoch 478/500\n",
      "72/72 - 0s - loss: 0.0795 - accuracy: 0.9688 - val_loss: 0.8853 - val_accuracy: 0.8333 - 264ms/epoch - 4ms/step\n",
      "Epoch 479/500\n",
      "72/72 - 0s - loss: 0.0909 - accuracy: 0.9618 - val_loss: 0.9686 - val_accuracy: 0.8646 - 262ms/epoch - 4ms/step\n",
      "Epoch 480/500\n",
      "72/72 - 0s - loss: 0.0818 - accuracy: 0.9583 - val_loss: 0.9215 - val_accuracy: 0.8646 - 265ms/epoch - 4ms/step\n",
      "Epoch 481/500\n",
      "72/72 - 0s - loss: 0.0769 - accuracy: 0.9653 - val_loss: 1.0362 - val_accuracy: 0.8646 - 293ms/epoch - 4ms/step\n",
      "Epoch 482/500\n",
      "72/72 - 0s - loss: 0.0827 - accuracy: 0.9583 - val_loss: 0.9322 - val_accuracy: 0.8750 - 264ms/epoch - 4ms/step\n",
      "Epoch 483/500\n",
      "72/72 - 0s - loss: 0.1357 - accuracy: 0.9444 - val_loss: 0.9227 - val_accuracy: 0.8646 - 268ms/epoch - 4ms/step\n",
      "Epoch 484/500\n",
      "72/72 - 0s - loss: 0.1456 - accuracy: 0.9410 - val_loss: 1.2245 - val_accuracy: 0.8542 - 265ms/epoch - 4ms/step\n",
      "Epoch 485/500\n",
      "72/72 - 0s - loss: 0.1944 - accuracy: 0.9340 - val_loss: 1.0002 - val_accuracy: 0.7917 - 283ms/epoch - 4ms/step\n",
      "Epoch 486/500\n",
      "72/72 - 0s - loss: 0.1274 - accuracy: 0.9479 - val_loss: 0.8624 - val_accuracy: 0.8125 - 272ms/epoch - 4ms/step\n",
      "Epoch 487/500\n",
      "72/72 - 0s - loss: 0.1414 - accuracy: 0.9306 - val_loss: 0.7247 - val_accuracy: 0.8750 - 267ms/epoch - 4ms/step\n",
      "Epoch 488/500\n",
      "72/72 - 0s - loss: 0.1896 - accuracy: 0.9271 - val_loss: 0.7888 - val_accuracy: 0.8750 - 269ms/epoch - 4ms/step\n",
      "Epoch 489/500\n",
      "72/72 - 0s - loss: 0.1124 - accuracy: 0.9549 - val_loss: 0.7605 - val_accuracy: 0.8750 - 279ms/epoch - 4ms/step\n",
      "Epoch 490/500\n",
      "72/72 - 0s - loss: 0.1035 - accuracy: 0.9549 - val_loss: 0.7612 - val_accuracy: 0.8854 - 276ms/epoch - 4ms/step\n",
      "Epoch 491/500\n",
      "72/72 - 0s - loss: 0.0786 - accuracy: 0.9688 - val_loss: 0.9241 - val_accuracy: 0.8646 - 283ms/epoch - 4ms/step\n",
      "Epoch 492/500\n",
      "72/72 - 0s - loss: 0.1403 - accuracy: 0.9479 - val_loss: 0.6864 - val_accuracy: 0.8750 - 268ms/epoch - 4ms/step\n",
      "Epoch 493/500\n",
      "72/72 - 0s - loss: 0.1176 - accuracy: 0.9410 - val_loss: 0.7073 - val_accuracy: 0.8854 - 284ms/epoch - 4ms/step\n",
      "Epoch 494/500\n",
      "72/72 - 0s - loss: 0.1071 - accuracy: 0.9479 - val_loss: 0.6591 - val_accuracy: 0.8958 - 271ms/epoch - 4ms/step\n",
      "Epoch 495/500\n",
      "72/72 - 0s - loss: 0.1053 - accuracy: 0.9479 - val_loss: 0.7921 - val_accuracy: 0.8333 - 274ms/epoch - 4ms/step\n",
      "Epoch 496/500\n",
      "72/72 - 0s - loss: 0.0634 - accuracy: 0.9688 - val_loss: 0.8482 - val_accuracy: 0.8750 - 268ms/epoch - 4ms/step\n",
      "Epoch 497/500\n",
      "72/72 - 0s - loss: 0.1016 - accuracy: 0.9618 - val_loss: 0.7644 - val_accuracy: 0.8542 - 277ms/epoch - 4ms/step\n",
      "Epoch 498/500\n",
      "72/72 - 0s - loss: 0.1392 - accuracy: 0.9444 - val_loss: 0.7054 - val_accuracy: 0.8438 - 270ms/epoch - 4ms/step\n",
      "Epoch 499/500\n",
      "72/72 - 0s - loss: 0.1484 - accuracy: 0.9375 - val_loss: 0.8327 - val_accuracy: 0.8750 - 266ms/epoch - 4ms/step\n",
      "Epoch 500/500\n",
      "72/72 - 0s - loss: 0.1029 - accuracy: 0.9549 - val_loss: 0.8372 - val_accuracy: 0.8750 - 299ms/epoch - 4ms/step\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, Y_train_encoded, epochs=500, validation_data=(x_test, Y_test_encoded), batch_size=4, verbose=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5ec40714",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://3877534b-33aa-45f6-b44e-ea0ba7244424/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://3877534b-33aa-45f6-b44e-ea0ba7244424/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000027A8C795400> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[56], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m pickle\u001b[39m.\u001b[39;49mdump(history, \u001b[39mopen\u001b[39;49m(\u001b[39m'\u001b[39;49m\u001b[39mlstm.pkl\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mwb\u001b[39;49m\u001b[39m'\u001b[39;49m))\n",
      "File \u001b[1;32mc:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py:315\u001b[0m, in \u001b[0;36mModel.__reduce__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__reduce__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    313\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuilt:\n\u001b[0;32m    314\u001b[0m     \u001b[39mreturn\u001b[39;00m (pickle_utils\u001b[39m.\u001b[39mdeserialize_model_from_bytecode,\n\u001b[1;32m--> 315\u001b[0m             pickle_utils\u001b[39m.\u001b[39;49mserialize_model_as_bytecode(\u001b[39mself\u001b[39;49m))\n\u001b[0;32m    316\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    317\u001b[0m     \u001b[39m# SavedModel (and hence serialize_model_as_bytecode) only support\u001b[39;00m\n\u001b[0;32m    318\u001b[0m     \u001b[39m# built models, but if the model is not built,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    322\u001b[0m     \u001b[39m# Thus we call up the superclass hierarchy to get an implementation of\u001b[39;00m\n\u001b[0;32m    323\u001b[0m     \u001b[39m# __reduce__ that can pickle this Model as a plain Python object.\u001b[39;00m\n\u001b[0;32m    324\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m(Model, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m__reduce__()\n",
      "File \u001b[1;32mc:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\saving\\pickle_utils.py:77\u001b[0m, in \u001b[0;36mserialize_model_as_bytecode\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m     75\u001b[0m       \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39mGFile(dest_path, \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m     76\u001b[0m         info \u001b[39m=\u001b[39m tarfile\u001b[39m.\u001b[39mTarInfo(name\u001b[39m=\u001b[39mos\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mrelpath(dest_path, temp_dir))\n\u001b[1;32m---> 77\u001b[0m         info\u001b[39m.\u001b[39msize \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39;49msize()\n\u001b[0;32m     78\u001b[0m         archive\u001b[39m.\u001b[39maddfile(tarinfo\u001b[39m=\u001b[39minfo, fileobj\u001b[39m=\u001b[39mf)\n\u001b[0;32m     79\u001b[0m tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39mrmtree(temp_dir)\n",
      "File \u001b[1;32mc:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py:99\u001b[0m, in \u001b[0;36mFileIO.size\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msize\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m     98\u001b[0m   \u001b[39m\"\"\"Returns the size of the file.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 99\u001b[0m   \u001b[39mreturn\u001b[39;00m stat(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__name)\u001b[39m.\u001b[39mlength\n",
      "File \u001b[1;32mc:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py:910\u001b[0m, in \u001b[0;36mstat\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m    897\u001b[0m \u001b[39m@tf_export\u001b[39m(v1\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mgfile.Stat\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m    898\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstat\u001b[39m(filename):\n\u001b[0;32m    899\u001b[0m   \u001b[39m\"\"\"Returns file statistics for a given path.\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \n\u001b[0;32m    901\u001b[0m \u001b[39m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[39m    errors.OpError: If the operation fails.\u001b[39;00m\n\u001b[0;32m    909\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 910\u001b[0m   \u001b[39mreturn\u001b[39;00m stat_v2(filename)\n",
      "File \u001b[1;32mc:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py:926\u001b[0m, in \u001b[0;36mstat_v2\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mio.gfile.stat\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    914\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstat_v2\u001b[39m(path):\n\u001b[0;32m    915\u001b[0m   \u001b[39m\"\"\"Returns file statistics for a given path.\u001b[39;00m\n\u001b[0;32m    916\u001b[0m \n\u001b[0;32m    917\u001b[0m \u001b[39m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    924\u001b[0m \u001b[39m    errors.OpError: If the operation fails.\u001b[39;00m\n\u001b[0;32m    925\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 926\u001b[0m   \u001b[39mreturn\u001b[39;00m _pywrap_file_io\u001b[39m.\u001b[39;49mStat(compat\u001b[39m.\u001b[39;49mpath_to_str(path))\n",
      "\u001b[1;31mNotFoundError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pickle.dump(history, open('lstm.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e39ceb4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot history\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8af853",
   "metadata": {},
   "source": [
    "# SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cb68eb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split  \n",
    "x_train, x_test, y_train, y_test= train_test_split(x, y, test_size= 0.25, random_state=0)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f899916e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b963d068",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc=SVC() \n",
    "\n",
    "# fit classi|fier to training set\n",
    "svc.fit(x_train,y_train)\n",
    "\n",
    "# make predictions on test set\n",
    "y_pred=svc.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "520a8370",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(svc, open('svm.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a95e6611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9479166666666666"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute and print accuracy score\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fedd99c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc=SVC(kernel='poly') \n",
    "\n",
    "# fit classi|fier to training set\n",
    "svc.fit(x_train,y_train)\n",
    "\n",
    "\n",
    "# make predictions on test set\n",
    "y_pred=svc.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "35f263b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(svc, open('svm_poly.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e41a350c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8645833333333334"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994b98fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61947a41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "b671c20432fcd147198c92e7f072af9e705f087eb990bee22b07f08caab9f630"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
